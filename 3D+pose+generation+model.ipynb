{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Ref:\n",
        "\n",
        "Most of the functions to preprocess data is from (Diffpose). And the structure of the denoiser is based from (Diffpose). Our team improved the beta scheduling in the diffusion generative model. And we modified and implemented the idea from (EDM) instead of the traditional (DDIM) to generate steps in the diffusion model.\n",
        "\n",
        "(Diffpose) https://github.com/GONGJIA0208/Diffpose\n",
        "\n",
        "(EDM) https://github.com/NVlabs/edm/tree/main\n",
        "\n",
        "(DDIM) https://github.com/ermongroup/ddim"
      ],
      "metadata": {
        "id": "f2Vai45ONWEd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EnvvAj0Vkkbl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "import time\n",
        "import glob\n",
        "import argparse\n",
        "\n",
        "import os.path as path\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.functional as F\n",
        "import scipy.sparse as sp\n",
        "import copy, math\n",
        "import torch.optim as optim\n",
        "from torch.nn import init\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.utils.data import Dataset\n",
        "from functools import reduce"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/E533-3D-Pose-Estimates-and-Diffusion-Method')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KODvS9IiPJU",
        "outputId": "c3eb9cd3-a462-4ab1-ab9e-9938ca81556f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "22UtEHSc7T9V"
      },
      "outputs": [],
      "source": [
        "from common.h36m_dataset import Human36mDataset\n",
        "from common.data_utils import fetch_me, read_3d_data_me, create_2d_data\n",
        "from common.loss import mpjpe, p_mpjpe\n",
        "from common.utils import test_calculation, define_error_list, print_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9PCyNUmuC5o"
      },
      "source": [
        "# Define parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZQ4qSuL3sx3F"
      },
      "outputs": [],
      "source": [
        "# Model:\n",
        "config_model = {\"hid_dim\": 96,\n",
        "    \"emd_dim\": 96,\n",
        "    \"coords_dim\": [5,5],\n",
        "    \"num_layer\": 5,\n",
        "    \"n_head\": 4,\n",
        "    \"dropout\": 0.25,\n",
        "    \"n_pts\": 17}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mpz1qBpahjsy"
      },
      "outputs": [],
      "source": [
        "# Training:\n",
        "batch_size = 1024\n",
        "n_epochs = 30\n",
        "num_workers = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aMLOu0BAw444"
      },
      "outputs": [],
      "source": [
        "# Testing:\n",
        "test_times = 1\n",
        "test_timesteps = 2\n",
        "test_num_diffusion_timesteps = 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VQp8E_oGjz5q"
      },
      "outputs": [],
      "source": [
        "# Optimizer:\n",
        "lr = 0.00002\n",
        "lr_gamma = 0.9\n",
        "eps = 0.00000001\n",
        "amsgrad = False\n",
        "decay = 60\n",
        "grad_clip = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mH0slcqFoMVu"
      },
      "outputs": [],
      "source": [
        "# diffusion:\n",
        "beta_schedule_1 = \"linear\"\n",
        "beta_schedule_2 = \"cosine\"\n",
        "beta_start = 0.0001\n",
        "beta_end = 0.001\n",
        "num_diffusion_timesteps = 51"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AiAeY4MWy3CZ"
      },
      "outputs": [],
      "source": [
        "eta = 0.0   # eta used to control the variances of sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "C2REoqYNpNtk"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KITFGR2thcI"
      },
      "source": [
        "# Create adjacent matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nNII4_oFm-i8"
      },
      "outputs": [],
      "source": [
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "381_HrStm8VE"
      },
      "outputs": [],
      "source": [
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "muc4PsWomwB-"
      },
      "outputs": [],
      "source": [
        "def adj_mx_from_edges(num_pts, edges, sparse=True):\n",
        "    edges = np.array(edges, dtype=np.int32)\n",
        "    data, i, j = np.ones(edges.shape[0]), edges[:, 0], edges[:, 1]\n",
        "    adj_mx = sp.coo_matrix((data, (i, j)), shape=(num_pts, num_pts), dtype=np.float32)\n",
        "\n",
        "    # build symmetric adjacency matrix\n",
        "    adj_mx = adj_mx + adj_mx.T.multiply(adj_mx.T > adj_mx) - adj_mx.multiply(adj_mx.T > adj_mx)\n",
        "    adj_mx = normalize(adj_mx + sp.eye(adj_mx.shape[0]))\n",
        "    if sparse:\n",
        "        adj_mx = sparse_mx_to_torch_sparse_tensor(adj_mx)\n",
        "    else:\n",
        "        adj_mx = torch.tensor(adj_mx.todense(), dtype=torch.float)\n",
        "    return adj_mx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVKBb71Mt2AA"
      },
      "source": [
        "# GCN diffusion model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7cpubBxt3wI"
      },
      "source": [
        "## ChebNet convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PeOk9lGWoJal"
      },
      "outputs": [],
      "source": [
        "class ChebConv(nn.Module):\n",
        "    \"\"\"\n",
        "    The ChebNet convolution operation.\n",
        "\n",
        "    :param in_c: int, number of input channels.\n",
        "    :param out_c: int, number of output channels.\n",
        "    :param K: int, the order of Chebyshev Polynomial.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_c, out_c, K, bias=True, normalize=True):\n",
        "        super(ChebConv, self).__init__()\n",
        "        self.normalize = normalize\n",
        "\n",
        "        self.weight = nn.Parameter(torch.Tensor(K + 1, 1, in_c, out_c))  # [K+1, 1, in_c, out_c]\n",
        "        init.xavier_normal_(self.weight)\n",
        "\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(1, 1, out_c))\n",
        "            init.zeros_(self.bias)\n",
        "        else:\n",
        "            self.register_parameter(\"bias\", None)\n",
        "\n",
        "        self.K = K + 1\n",
        "\n",
        "    def forward(self, inputs, graph):\n",
        "        \"\"\"\n",
        "        :param inputs: the input data, [B, N, C]\n",
        "        :param graph: the graph structure, [N, N]\n",
        "        :return: convolution result, [B, N, D]\n",
        "        \"\"\"\n",
        "        L = ChebConv.get_laplacian(graph, self.normalize)  # [N, N]\n",
        "        mul_L = self.cheb_polynomial(L).unsqueeze(1)   # [K, 1, N, N]\n",
        "\n",
        "        result = torch.matmul(mul_L, inputs)  # [K, B, N, C]\n",
        "\n",
        "        result = torch.matmul(result, self.weight)  # [K, B, N, D]\n",
        "        result = torch.sum(result, dim=0) + self.bias  # [B, N, D]\n",
        "\n",
        "        return result\n",
        "\n",
        "    def cheb_polynomial(self, laplacian):\n",
        "        \"\"\"\n",
        "        Compute the Chebyshev Polynomial, according to the graph laplacian.\n",
        "\n",
        "        :param laplacian: the graph laplacian, [N, N].\n",
        "        :return: the multi order Chebyshev laplacian, [K, N, N].\n",
        "        \"\"\"\n",
        "        N = laplacian.size(0)  # [N, N]\n",
        "        multi_order_laplacian = torch.zeros([self.K, N, N], device=laplacian.device, dtype=torch.float)  # [K, N, N]\n",
        "        multi_order_laplacian[0] = torch.eye(N, device=laplacian.device, dtype=torch.float)\n",
        "\n",
        "        if self.K == 1:\n",
        "            return multi_order_laplacian\n",
        "        else:\n",
        "            multi_order_laplacian[1] = laplacian\n",
        "            if self.K == 2:\n",
        "                return multi_order_laplacian\n",
        "            else:\n",
        "                for k in range(2, self.K):\n",
        "                    multi_order_laplacian[k] = 2 * torch.mm(laplacian, multi_order_laplacian[k-1]) - \\\n",
        "                                               multi_order_laplacian[k-2]\n",
        "\n",
        "        return multi_order_laplacian\n",
        "\n",
        "    @staticmethod\n",
        "    def get_laplacian(graph, normalize):\n",
        "        \"\"\"\n",
        "        return the laplacian of the graph.\n",
        "\n",
        "        :param graph: the graph structure without self loop, [N, N].\n",
        "        :param normalize: whether to used the normalized laplacian.\n",
        "        :return: graph laplacian.\n",
        "        \"\"\"\n",
        "        if normalize:\n",
        "\n",
        "            D = torch.diag(torch.sum(graph, dim=-1) ** (-1 / 2))\n",
        "            L = torch.eye(graph.size(0), device=graph.device, dtype=graph.dtype) - torch.mm(torch.mm(D, graph), D)\n",
        "        else:\n",
        "            D = torch.diag(torch.sum(graph, dim=-1))\n",
        "            L = D - graph\n",
        "        return L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8FojexjuJPs"
      },
      "source": [
        "## Define Multiheaded attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_nO1jpPCtU6u"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.linears = nn.ModuleList([copy.deepcopy(nn.Linear(d_model, d_model)) for _ in range(4)])\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "        nbatches = query.size(0)\n",
        "\n",
        "        Q, K, V = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "                   for l, x in zip(self.linears, (query, key, value))]\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        p_attn = F.softmax(scores, dim=-1)\n",
        "        p_attn = self.dropout(p_attn)\n",
        "        x = torch.matmul(p_attn, V)\n",
        "        self.attn = p_attn\n",
        "\n",
        "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
        "\n",
        "        return self.linears[-1](x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVjBo8gtxNWH"
      },
      "source": [
        "## Define GCN layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iqEr7EWNxQWt"
      },
      "outputs": [],
      "source": [
        "class LAM_Gconv(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features, out_features, activation=nn.ReLU(inplace=True)):\n",
        "        super(LAM_Gconv, self).__init__()\n",
        "        self.fc = nn.Linear(in_features=in_features, out_features=out_features)\n",
        "        self.activation = activation\n",
        "\n",
        "    def laplacian(self, A_hat):\n",
        "        D_hat = (torch.sum(A_hat, 0) + 1e-5) ** (-0.5)\n",
        "        L = D_hat * A_hat * D_hat\n",
        "        return L\n",
        "\n",
        "    def laplacian_batch(self, A_hat):\n",
        "        batch, N = A_hat.shape[:2]\n",
        "        D_hat = (torch.sum(A_hat, 1) + 1e-5) ** (-0.5)\n",
        "        L = D_hat.view(batch, N, 1) * A_hat * D_hat.view(batch, 1, N)\n",
        "        return L\n",
        "\n",
        "    def forward(self, X, A):\n",
        "        batch = X.size(0)\n",
        "        A_hat = A.unsqueeze(0).repeat(batch, 1, 1)\n",
        "        X = self.fc(torch.bmm(self.laplacian_batch(A_hat), X))\n",
        "        if self.activation is not None:\n",
        "            X = self.activation(X)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8hgjIBvw8_a"
      },
      "source": [
        "## Define graphnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vroPzV1Xw_FK"
      },
      "outputs": [],
      "source": [
        "class GraphNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features=2, out_features=2, n_pts=21):\n",
        "        super(GraphNet, self).__init__()\n",
        "\n",
        "        self.A_hat = Parameter(torch.eye(n_pts).float(), requires_grad=True)\n",
        "        self.gconv1 = LAM_Gconv(in_features, in_features * 2)\n",
        "        self.gconv2 = LAM_Gconv(in_features * 2, out_features, activation=None)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X_0 = self.gconv1(X, self.A_hat)\n",
        "        X_1 = self.gconv2(X_0, self.A_hat)\n",
        "        return X_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyoliFmyxoz_"
      },
      "source": [
        "## Define residual differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDmHDsRKx_hd"
      },
      "source": [
        "### Define _GraphConv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CSEwNyVRyFBu"
      },
      "outputs": [],
      "source": [
        "class _GraphConv(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, p_dropout=None):\n",
        "        super(_GraphConv, self).__init__()\n",
        "\n",
        "        self.gconv = ChebConv(input_dim, output_dim, K=2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        if p_dropout is not None:\n",
        "            self.dropout = nn.Dropout(p_dropout)\n",
        "        else:\n",
        "            self.dropout = None\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = self.gconv(x, adj)\n",
        "        if self.dropout is not None:\n",
        "            x = self.dropout(self.relu(x))\n",
        "\n",
        "        x = self.relu(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6THx_lwWxqUY"
      },
      "outputs": [],
      "source": [
        "class _ResChebGC_diff(nn.Module):\n",
        "    def __init__(self, adj, input_dim, output_dim, emd_dim, hid_dim, p_dropout):\n",
        "        super(_ResChebGC_diff, self).__init__()\n",
        "        self.adj = adj\n",
        "        self.gconv1 = _GraphConv(input_dim, hid_dim, p_dropout)\n",
        "        self.gconv2 = _GraphConv(hid_dim, output_dim, p_dropout)\n",
        "        ### time embedding ###\n",
        "        self.temb_proj = torch.nn.Linear(emd_dim,hid_dim)\n",
        "\n",
        "    def forward(self, x, temb):\n",
        "        residual = x\n",
        "        out = self.gconv1(x, self.adj)\n",
        "        out = out + self.temb_proj(temb*torch.sigmoid(temb))[:, None, :]\n",
        "        out = self.gconv2(out, self.adj)\n",
        "        return residual + out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR1PIP0h0uRf"
      },
      "source": [
        "## Define encoder for self-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cj4nsqi60-5v"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        # features=layer.size=512\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EjOmwR1o0433"
      },
      "outputs": [],
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "\n",
        "    def __init__(self, size, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        return x + self.dropout(sublayer(self.norm(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Gp7R4-Ek0tyT"
      },
      "outputs": [],
      "source": [
        "class GraAttenLayer(nn.Module):\n",
        "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
        "\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super(GraAttenLayer, self).__init__()\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = nn.ModuleList([copy.deepcopy(SublayerConnection(size, dropout)) for _ in range(2)])\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        return self.sublayer[1](x, self.feed_forward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRR20IQg1atJ"
      },
      "source": [
        "## Define timestep embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "E9MyiDS01aKU"
      },
      "outputs": [],
      "source": [
        "def SinusoidalEmbeddings(timesteps, embedding_dim):\n",
        "\n",
        "    half_dim = embedding_dim // 2\n",
        "    emb = math.log(10000) / (half_dim - 1)\n",
        "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
        "    emb = emb.to(device=timesteps.device)\n",
        "    emb = timesteps.float()[:, None] * emb[None, :]\n",
        "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
        "    return emb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOH9QsQruTuI"
      },
      "source": [
        "# Build GCN diffusion model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-2lsjjVWnsTn"
      },
      "outputs": [],
      "source": [
        "class GCNdiff(nn.Module):\n",
        "    def __init__(self, adj, config):\n",
        "        super(GCNdiff, self).__init__()\n",
        "\n",
        "        self.adj = adj\n",
        "        self.config = config\n",
        "        ### load gcn configuration ###\n",
        "        self.hid_dim, self.emd_dim, self.coords_dim, num_layers, n_head, dropout, n_pts = \\\n",
        "            config['hid_dim'], config['emd_dim'], config['coords_dim'], \\\n",
        "                config['num_layer'], config['n_head'], config['dropout'], config['n_pts']\n",
        "\n",
        "        self.hid_dim = self.hid_dim\n",
        "        self.emd_dim = self.hid_dim*4\n",
        "\n",
        "        ### Generate Graphformer  ###\n",
        "        self.n_layers = num_layers\n",
        "\n",
        "        _gconv_input = ChebConv(in_c=self.coords_dim[0], out_c=self.hid_dim, K=2)\n",
        "        _gconv_layers = []\n",
        "        _attention_layer = []\n",
        "\n",
        "        dim_model = self.hid_dim\n",
        "        c = copy.deepcopy\n",
        "        attn = MultiHeadedAttention(n_head, dim_model)\n",
        "        gcn = GraphNet(in_features=dim_model, out_features=dim_model, n_pts=n_pts)\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            _gconv_layers.append(_ResChebGC_diff(adj=adj, input_dim=self.hid_dim, output_dim=self.hid_dim,\n",
        "                emd_dim=self.emd_dim, hid_dim=self.hid_dim, p_dropout=0.1))\n",
        "            _attention_layer.append(GraAttenLayer(dim_model, c(attn), c(gcn), dropout))\n",
        "\n",
        "        self.gconv_input = _gconv_input\n",
        "        self.gconv_layers = nn.ModuleList(_gconv_layers)\n",
        "        self.atten_layers = nn.ModuleList(_attention_layer)\n",
        "        self.gconv_output = ChebConv(in_c=dim_model, out_c=self.coords_dim[1], K=2)\n",
        "\n",
        "\n",
        "        ### diffusion configuration  ###\n",
        "        self.temb = nn.Module()\n",
        "        self.temb.dense = nn.ModuleList([\n",
        "            torch.nn.Linear(self.hid_dim,self.emd_dim),\n",
        "            torch.nn.Linear(self.emd_dim,self.emd_dim),\n",
        "        ])\n",
        "\n",
        "\n",
        "    def forward(self, x, mask, t, cemd):\n",
        "        # timestep embedding\n",
        "        temb = SinusoidalEmbeddings(t, self.hid_dim)\n",
        "        temb = self.temb.dense[0](temb)\n",
        "        temb = temb*torch.sigmoid(temb)\n",
        "        temb = self.temb.dense[1](temb)\n",
        "\n",
        "        out = self.gconv_input(x, self.adj)\n",
        "        for i in range(self.n_layers):\n",
        "            out = self.atten_layers[i](out, mask)\n",
        "            out = self.gconv_layers[i](out, temb)\n",
        "        out = self.gconv_output(out, self.adj)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mkkYIA0tnJ6"
      },
      "source": [
        "# Create diffusion model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8z84SbvckniT"
      },
      "outputs": [],
      "source": [
        "def create_diffusion_model():\n",
        "    edges = torch.tensor([[0, 1], [1, 2], [2, 3],\n",
        "                        [0, 4], [4, 5], [5, 6],\n",
        "                        [0, 7], [7, 8], [8, 9], [9,10],\n",
        "                        [8, 11], [11, 12], [12, 13],\n",
        "                        [8, 14], [14, 15], [15, 16]], dtype=torch.long)\n",
        "    adj = adj_mx_from_edges(num_pts=17, edges=edges, sparse=False)\n",
        "    model_diff = GCNdiff(adj.to(device), config_model).to(device)\n",
        "    model_diff = torch.nn.DataParallel(model_diff)\n",
        "    return model_diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DeIaqxF3ILQ8"
      },
      "outputs": [],
      "source": [
        "model_diff = create_diffusion_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCerFReM5PKA"
      },
      "source": [
        "# GCN Pose model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "fVo-H42k5ecH"
      },
      "outputs": [],
      "source": [
        "class _ResChebGC(nn.Module):\n",
        "    def __init__(self, adj, input_dim, output_dim, hid_dim, p_dropout):\n",
        "        super(_ResChebGC, self).__init__()\n",
        "        self.adj = adj\n",
        "        self.gconv1 = _GraphConv(input_dim, hid_dim, p_dropout)\n",
        "        self.gconv2 = _GraphConv(hid_dim, output_dim, p_dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.gconv1(x, self.adj)\n",
        "        out = self.gconv2(out, self.adj)\n",
        "        return residual + out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nmqPzxt_5LeY"
      },
      "outputs": [],
      "source": [
        "class GCNpose(nn.Module):\n",
        "    def __init__(self, adj, config):\n",
        "        super(GCNpose, self).__init__()\n",
        "\n",
        "        self.adj = adj\n",
        "        self.config = config\n",
        "        ### load gcn configuration ###\n",
        "        self.hid_dim, self.emd_dim, self.coords_dim, num_layers, n_head, dropout, n_pts = \\\n",
        "            config['hid_dim'], config['emd_dim'], config['coords_dim'], \\\n",
        "                config['num_layer'], config['n_head'], config['dropout'], config['n_pts']\n",
        "\n",
        "        self.hid_dim = self.hid_dim\n",
        "        self.emd_dim = self.hid_dim*4\n",
        "\n",
        "        ### Generate Graphformer  ###\n",
        "        self.n_layers = num_layers\n",
        "\n",
        "        _gconv_input = ChebConv(in_c=self.coords_dim[0], out_c=self.hid_dim, K=2)\n",
        "        _gconv_layers = []\n",
        "        _attention_layer = []\n",
        "\n",
        "        dim_model = self.hid_dim\n",
        "        c = copy.deepcopy\n",
        "        attn = MultiHeadedAttention(n_head, dim_model)\n",
        "        gcn = GraphNet(in_features=dim_model, out_features=dim_model, n_pts=n_pts)\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            _gconv_layers.append(_ResChebGC(adj=adj, input_dim=self.hid_dim, output_dim=self.hid_dim,\n",
        "                                            hid_dim=self.hid_dim, p_dropout=0.1))\n",
        "            _attention_layer.append(GraAttenLayer(dim_model, c(attn), c(gcn), dropout))\n",
        "\n",
        "        self.gconv_input = _gconv_input\n",
        "        self.gconv_layers = nn.ModuleList(_gconv_layers)\n",
        "        self.atten_layers = nn.ModuleList(_attention_layer)\n",
        "        self.gconv_output = ChebConv(in_c=dim_model, out_c=3, K=2)\n",
        "\n",
        "\n",
        "        ### diffusion configuration  ###\n",
        "        self.temb = nn.Module()\n",
        "        self.temb.dense = nn.ModuleList([\n",
        "            torch.nn.Linear(self.hid_dim,self.emd_dim),\n",
        "            torch.nn.Linear(self.emd_dim,self.emd_dim),\n",
        "        ])\n",
        "\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        out = self.gconv_input(x, self.adj)\n",
        "        for i in range(self.n_layers):\n",
        "            out = self.atten_layers[i](out, mask)\n",
        "            out = self.gconv_layers[i](out)\n",
        "        out = self.gconv_output(out, self.adj)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDSbkmFQ4xS_"
      },
      "source": [
        "# Create pose model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pnbLMoiT4u4m"
      },
      "outputs": [],
      "source": [
        "def create_pose_model():\n",
        "\n",
        "        # [input dimension u v, output dimension x y z]\n",
        "        config_model['coords_dim'] = [2,3]\n",
        "        edges = torch.tensor([[0, 1], [1, 2], [2, 3],\n",
        "                            [0, 4], [4, 5], [5, 6],\n",
        "                            [0, 7], [7, 8], [8, 9], [9,10],\n",
        "                            [8, 11], [11, 12], [12, 13],\n",
        "                            [8, 14], [14, 15], [15, 16]], dtype=torch.long)\n",
        "        adj = adj_mx_from_edges(num_pts=17, edges=edges, sparse=False)\n",
        "        model_pose = GCNpose(adj.to(device), config_model).to(device)\n",
        "        model_pose = torch.nn.DataParallel(model_pose)\n",
        "        logging.info('initialize model randomly')\n",
        "        return model_pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "iH53TlNBIU-X"
      },
      "outputs": [],
      "source": [
        "model_pose = create_pose_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feZeHMdD6udY"
      },
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "G2WcNtaZ6thx"
      },
      "outputs": [],
      "source": [
        "dataset = Human36mDataset(\"./data/data_3d_h36m.npz\")\n",
        "subjects_train = ['S1', 'S5', 'S6', 'S7', 'S8']\n",
        "subjects_test = ['S9', 'S11']\n",
        "dataset = read_3d_data_me(dataset)\n",
        "keypoints = create_2d_data(\"./data/data_2d_h36m_cpn_ft_h36m_dbb_gmm.npz\", dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnaXgFUoHv_i"
      },
      "source": [
        "# Train the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te7Xy-ZAiDgm"
      },
      "source": [
        "## Generate pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6c6fvo78iFZR"
      },
      "outputs": [],
      "source": [
        "class PoseGenerator_gmm(Dataset):\n",
        "    def __init__(self, poses_3d, poses_2d_gmm, actions, camerapara):\n",
        "        assert poses_3d is not None\n",
        "\n",
        "        self._poses_3d = np.concatenate(poses_3d)\n",
        "        self._poses_2d_gmm = np.concatenate(poses_2d_gmm)\n",
        "        self._actions = reduce(lambda x, y: x + y, actions)\n",
        "        self._camerapara = np.concatenate(camerapara)\n",
        "        self._kernel_n = self._poses_2d_gmm.shape[2]\n",
        "\n",
        "        self._poses_3d[:,:,:] = self._poses_3d[:,:,:]-self._poses_3d[:,:1,:]\n",
        "\n",
        "        assert self._poses_3d.shape[0] == self._poses_2d_gmm.shape[0] and self._poses_3d.shape[0] == len(self._actions)\n",
        "        print('Generating {} poses...'.format(len(self._actions)))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        out_pose_3d = self._poses_3d[index]\n",
        "        out_pose_2d_gmm = self._poses_2d_gmm[index]\n",
        "        out_action = self._actions[index]\n",
        "        out_camerapara = self._camerapara[index]\n",
        "\n",
        "        # randomly select a kernel from gmm\n",
        "        out_pose_2d_kernel = np.zeros([out_pose_2d_gmm.shape[0],out_pose_2d_gmm.shape[2]])\n",
        "        for i in range(out_pose_2d_gmm.shape[0]):\n",
        "            out_pose_2d_kernel[i] = out_pose_2d_gmm[i,np.random.choice(self._kernel_n, 1, p=out_pose_2d_gmm[i,:,0]).item()]\n",
        "\n",
        "        # generate uvxyz and uvxyz noise scale\n",
        "        kernel_mean = out_pose_2d_kernel[:,1:3]\n",
        "        kernel_variance = out_pose_2d_kernel[:,3:]\n",
        "\n",
        "        out_pose_uvxyz = np.concatenate((kernel_mean,out_pose_3d),axis=1)\n",
        "        out_pose_noise_scale = np.concatenate((kernel_variance,np.ones(out_pose_3d.shape)),axis=1)\n",
        "\n",
        "        out_pose_uvxyz = torch.from_numpy(out_pose_uvxyz).float()\n",
        "        out_pose_noise_scale = torch.from_numpy(out_pose_noise_scale).float()\n",
        "        out_pose_2d = torch.from_numpy(kernel_mean).float()\n",
        "        out_pose_3d = torch.from_numpy(out_pose_3d).float()\n",
        "        out_camerapara = torch.from_numpy(out_camerapara).float()\n",
        "\n",
        "        return out_pose_uvxyz, out_pose_noise_scale, out_pose_2d, out_pose_3d, out_action, out_camerapara\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "hYKHHf19fWBk"
      },
      "outputs": [],
      "source": [
        "cudnn.benchmark = True\n",
        "best_p1, best_epoch = 1000, 0\n",
        "stride = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7XOxcpr4gIQL"
      },
      "outputs": [],
      "source": [
        "poses_train, poses_train_2d, actions_train, camerapara_train\\\n",
        "            = fetch_me(subjects_train, dataset, keypoints, None, stride)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI-pfJd7hZa_",
        "outputId": "07027c09-8e4d-481a-ee26-ca99cd158770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 1559752 poses...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "data_loader = train_loader = data.DataLoader(\n",
        "            PoseGenerator_gmm(poses_train, poses_train_2d, actions_train, camerapara_train),\n",
        "            batch_size=batch_size, shuffle=True,\\\n",
        "                num_workers=num_workers, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMEUiuE7lmus"
      },
      "source": [
        "## Implement exponential moving average(EMA) in the DDIM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "MtmnVzAsltdZ"
      },
      "outputs": [],
      "source": [
        "class EMAHelper(object):\n",
        "    def __init__(self, mu=0.999):\n",
        "        self.mu = mu\n",
        "        self.shadow = {}\n",
        "\n",
        "    def register(self, module):\n",
        "        if isinstance(module, nn.DataParallel):\n",
        "            module = module.module\n",
        "        for name, param in module.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def update(self, module):\n",
        "        if isinstance(module, nn.DataParallel):\n",
        "            module = module.module\n",
        "        for name, param in module.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name].data = (\n",
        "                    1. - self.mu) * param.data + self.mu * self.shadow[name].data\n",
        "\n",
        "    def ema(self, module):\n",
        "        if isinstance(module, nn.DataParallel):\n",
        "            module = module.module\n",
        "        for name, param in module.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                param.data.copy_(self.shadow[name].data)\n",
        "\n",
        "    def ema_copy(self, module):\n",
        "        if isinstance(module, nn.DataParallel):\n",
        "            inner_module = module.module\n",
        "            module_copy = type(inner_module)(\n",
        "                inner_module.config).to(inner_module.config.device)\n",
        "            module_copy.load_state_dict(inner_module.state_dict())\n",
        "            module_copy = nn.DataParallel(module_copy)\n",
        "        else:\n",
        "            module_copy = type(module)(module.config).to(module.config.device)\n",
        "            module_copy.load_state_dict(module.state_dict())\n",
        "        # module_copy = copy.deepcopy(module)\n",
        "        self.ema(module_copy)\n",
        "        return module_copy\n",
        "\n",
        "    def state_dict(self):\n",
        "        return self.shadow\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        self.shadow = state_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "3FHlmPtFkXd8"
      },
      "outputs": [],
      "source": [
        "ema_helper = EMAHelper()\n",
        "ema_helper.register(model_diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WwC67iYVioDa"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model_diff.parameters(), lr=lr, weight_decay=0.000,\n",
        "                          betas=(0.9, 0.999), amsgrad=amsgrad,\n",
        "                          eps=eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "P5nLFn-UmA4h"
      },
      "outputs": [],
      "source": [
        "start_epoch, step = 0, 0\n",
        "lr_init, decay, gamma = lr, decay, lr_gamma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdIOcdj8m-wa"
      },
      "source": [
        "## Computes and stores the average and current value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "4B0VmrqXm-Fi"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def lr_decay(optimizer, step, lr, decay_step, gamma):\n",
        "    lr = lr * gamma ** (step / decay_step)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhpA9TASovR5"
      },
      "source": [
        "## Generate Diffusion sequence parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "dfnt89Zuotnd"
      },
      "outputs": [],
      "source": [
        "def get_beta_schedule(beta_schedule, *, beta_start, beta_end, num_diffusion_timesteps):\n",
        "\n",
        "\n",
        "    if beta_schedule == \"cosine\":\n",
        "        x = np.linspace(beta_start, beta_end, num_diffusion_timesteps+1, dtype=np.float64)\n",
        "        alphas = np.cos(((x / num_diffusion_timesteps) + 0.008) / (1 + 0.008) * math.pi * 0.5) ** 2\n",
        "        alphas = alphas / alphas[0]\n",
        "        betas = 1 - (alphas[1:] / alphas[:-1])\n",
        "        betas = np.clip(betas, 0.01, 0.99)\n",
        "    elif beta_schedule == \"linear\":\n",
        "        betas = np.linspace(\n",
        "            beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64\n",
        "        )\n",
        "    assert betas.shape == (num_diffusion_timesteps,)\n",
        "    return betas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "yzoK-qlTn8wj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "e3ff2287-e557-4104-dd25-819e00301461"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-735dbc6d99a2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate Diffusion sequence parameters using linear beta schedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m betas_1 = get_beta_schedule(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbeta_schedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta_schedule_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbeta_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbeta_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta_end\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-6f6da1c9e592>\u001b[0m in \u001b[0;36mget_beta_schedule\u001b[0;34m(beta_schedule, beta_start, beta_end, num_diffusion_timesteps)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbeta_schedule\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         betas = np.linspace(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mclip\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: _clip_dispatcher() missing 1 required positional argument: 'a_max'"
          ]
        }
      ],
      "source": [
        "# Generate Diffusion sequence parameters using linear beta schedule\n",
        "betas_1 = get_beta_schedule(\n",
        "    beta_schedule=beta_schedule_2,\n",
        "    beta_start=beta_start,\n",
        "    beta_end=beta_end,\n",
        "    num_diffusion_timesteps=num_diffusion_timesteps,\n",
        ")\n",
        "betas_1 = torch.from_numpy(betas_1).float().to(device)\n",
        "num_timesteps = betas_1.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Diffusion sequence parameters using cosine beta schedule\n",
        "betas_2 = get_beta_schedule(\n",
        "    beta_schedule=beta_schedule_2,\n",
        "    beta_start=beta_start,\n",
        "    beta_end=beta_end,\n",
        "    num_diffusion_timesteps=num_diffusion_timesteps,\n",
        ")\n",
        "betas_2 = torch.from_numpy(betas_2).float().to(device)\n",
        "num_timesteps = betas_2.shape[0]"
      ],
      "metadata": {
        "id": "oM_IJ6WScv2Z"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "lEqhFkHSqf1a"
      },
      "outputs": [],
      "source": [
        "src_mask = torch.tensor([[[True, True, True, True, True, True, True, True, True, True,\n",
        "                                True, True, True, True, True, True, True]]]).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEY7of5j5hp8"
      },
      "source": [
        "## Generalized steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "atCSUN6B5ob0"
      },
      "outputs": [],
      "source": [
        "def compute_alpha(beta, t):\n",
        "    beta = torch.cat([torch.zeros(1).to(beta.device), beta], dim=0)\n",
        "    a = (1 - beta).cumprod(dim=0).index_select(0, t + 1).view(-1, 1, 1)\n",
        "    return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "xvueeVOB5g0V"
      },
      "outputs": [],
      "source": [
        "def generalized_steps(x, src_mask, seq, model, b, **kwargs):\n",
        "    with torch.no_grad():\n",
        "        n = x.size(0)\n",
        "        seq_next = [-1] + list(seq[:-1])\n",
        "        x0_preds = []\n",
        "        xs = [x]\n",
        "        for i, j in zip(reversed(seq), reversed(seq_next)):\n",
        "            t = (torch.ones(n) * i).to(device)\n",
        "            next_t = (torch.ones(n) * j).to(device)\n",
        "            at = compute_alpha(b, t.long())\n",
        "            at_next = compute_alpha(b, next_t.long())\n",
        "            xt = xs[-1]\n",
        "            et = model(xt, src_mask, t.float(), 0)\n",
        "            x0_t = (xt - et * (1 - at).sqrt()) / at.sqrt()\n",
        "            x0_preds.append(x0_t)\n",
        "            c1 = (\n",
        "                kwargs.get(\"eta\", 0) * ((1 - at / at_next) * (1 - at_next) / (1 - at)).sqrt()\n",
        "            )\n",
        "            c2 = ((1 - at_next) - c1 ** 2).sqrt()\n",
        "            xt_next = at_next.sqrt() * x0_t + c1 * torch.randn_like(x) + c2 * et\n",
        "            xs.append(xt_next)\n",
        "\n",
        "    return xs, x0_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use second order method to generate steps"
      ],
      "metadata": {
        "id": "bDuzCTVIx5TD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generalized_steps_edm(x, src_mask, seq, model, b):\n",
        "    with torch.no_grad():\n",
        "        n = x.size(0)\n",
        "        seq_next = [-1] + list(seq[:-1])\n",
        "        x0_preds = []\n",
        "        xs = [x]\n",
        "        for i, j in zip(reversed(seq), reversed(seq_next)):\n",
        "            t = (torch.ones(n) * i).to(device)\n",
        "            gamma = min(40 / num_diffusion_timesteps, np.sqrt(2) - 1) if 0.003 <= i <= 0.007 else 0\n",
        "            t_hat = i + gamma * i\n",
        "            next_t = (torch.ones(n) * j).to(device)\n",
        "            at = compute_alpha(b, t.long())\n",
        "            at_next = compute_alpha(b, next_t.long())\n",
        "            xt = xs[-1]\n",
        "            x_hat = xt + np.sqrt(t_hat ** 2 - i ** 2) * 1.003 * torch.randn_like(x)\n",
        "\n",
        "            denoised = model(x_hat, src_mask, t.float(), 0)\n",
        "\n",
        "            d_cur = (xt - denoised * (1 - at).sqrt())\n",
        "            a_ratio = at_next / at\n",
        "            x_next = a_ratio.sqrt() * d_cur\n",
        "\n",
        "            # Apply 2nd order correction.\n",
        "            if i < num_diffusion_timesteps - 1:\n",
        "                denoised_2 = model(x_next, src_mask, next_t.float(), 0)\n",
        "                eps = ((1-at_next+at)/(1-at)-1/(a_ratio*(1-at))).sqrt()\n",
        "                drift = (1-at_next-(1-at_next+at)/(1-at)+1/(a_ratio*(1-at))).sqrt()\n",
        "                x_next += eps * torch.randn_like(x) + drift*denoised_2\n",
        "\n",
        "            xs.append(x_next)\n",
        "\n",
        "    return xs, x0_preds"
      ],
      "metadata": {
        "id": "g-Pyadx_xKDD"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generalized_steps_edm1(x, src_mask, seq, model, b):\n",
        "    with torch.no_grad():\n",
        "        n = x.size(0)\n",
        "        seq_next = [-1] + list(seq[:-1])\n",
        "        x0_preds = []\n",
        "        xs = [x]\n",
        "        for i, j in zip(reversed(seq), reversed(seq_next)):\n",
        "            t = (torch.ones(n) * i).to(device)\n",
        "            gamma = min(40 / num_diffusion_timesteps, np.sqrt(2) - 1) if 0.003 <= i <= 0.007 else 0\n",
        "            t_hat = i + gamma * i\n",
        "            next_t = (torch.ones(n) * j).to(device)\n",
        "            at = compute_alpha(b, t.long())\n",
        "            at_next = compute_alpha(b, next_t.long())\n",
        "            xt = xs[-1]\n",
        "            x_hat = xt + np.sqrt(t_hat ** 2 - i ** 2) * 1.003 * torch.randn_like(x)\n",
        "\n",
        "\n",
        "            denoised = model(x_hat, src_mask, t.float(), 0)\n",
        "            x_diff = (xt - denoised) / t_hat\n",
        "            x_next = x_hat + (j - t_hat) * x_diff\n",
        "\n",
        "            # Apply 2nd order correction.\n",
        "            if i != seq[1] and i != seq[0]:\n",
        "                denoised_2 = model(x_next, src_mask, next_t.float(), 0)\n",
        "                d_prime = (x_next - denoised_2) / j\n",
        "                x_next = x_hat + (j - t_hat) * (0.5 * x_diff + 0.5 * d_prime)\n",
        "\n",
        "            xs.append(x_next)\n",
        "\n",
        "    return xs, x0_preds"
      ],
      "metadata": {
        "id": "2_sslMeG8116"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjgjGOhJ3MCB"
      },
      "source": [
        "## Define mpjpe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "fQes9BM_3LXz"
      },
      "outputs": [],
      "source": [
        "def mpjpe(predicted, target):\n",
        "    \"\"\"\n",
        "    Mean per-joint position error (i.e. mean Euclidean distance),\n",
        "    often referred to as \"Protocol #1\" in many papers.\n",
        "    \"\"\"\n",
        "    return torch.mean(torch.norm(predicted - target, dim=len(target.shape) - 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "9nyb9-nq3bJb"
      },
      "outputs": [],
      "source": [
        "def p_mpjpe(predicted, target):\n",
        "    \"\"\"\n",
        "    Pose error: MPJPE after rigid alignment (scale, rotation, and translation),\n",
        "    often referred to as \"Protocol #2\" in many papers.\n",
        "    \"\"\"\n",
        "    assert predicted.shape == target.shape\n",
        "\n",
        "    muX = np.mean(target, axis=1, keepdims=True)\n",
        "    muY = np.mean(predicted, axis=1, keepdims=True)\n",
        "\n",
        "    X0 = target - muX\n",
        "    Y0 = predicted - muY\n",
        "\n",
        "    normX = np.sqrt(np.sum(X0 ** 2, axis=(1, 2), keepdims=True))\n",
        "    normY = np.sqrt(np.sum(Y0 ** 2, axis=(1, 2), keepdims=True))\n",
        "\n",
        "    X0 /= normX\n",
        "    Y0 /= normY\n",
        "\n",
        "    H = np.matmul(X0.transpose(0, 2, 1), Y0)\n",
        "    U, s, Vt = np.linalg.svd(H)\n",
        "    V = Vt.transpose(0, 2, 1)\n",
        "    R = np.matmul(V, U.transpose(0, 2, 1))\n",
        "\n",
        "    # Avoid improper rotations (reflections), i.e. rotations with det(R) = -1\n",
        "    sign_detR = np.sign(np.expand_dims(np.linalg.det(R), axis=1))\n",
        "    V[:, :, -1] *= sign_detR\n",
        "    s[:, -1] *= sign_detR.flatten()\n",
        "    R = np.matmul(V, U.transpose(0, 2, 1))  # Rotation\n",
        "\n",
        "    tr = np.expand_dims(np.sum(s, axis=1, keepdims=True), axis=2)\n",
        "\n",
        "    a = tr * normX / normY  # Scale\n",
        "    t = muX - a * np.matmul(muY, R)  # Translation\n",
        "\n",
        "    # Perform rigid transformation on the input\n",
        "    predicted_aligned = a * np.matmul(predicted, R) + t\n",
        "\n",
        "    # Return MPJPE\n",
        "    return np.mean(np.linalg.norm(predicted_aligned - target, axis=len(target.shape) - 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwNk9OnwzInu"
      },
      "source": [
        "## Find the best epoch with best MPJPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "qIIQSNqEsInc"
      },
      "outputs": [],
      "source": [
        "def test_hyber(betas = betas_1, test_times=1, test_timesteps=2, test_num_diffusion_timesteps=24, device=device, is_train=False, edm=False, edm_1=False):\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    test_times, test_timesteps, test_num_diffusion_timesteps, stride = \\\n",
        "        test_times, test_timesteps, test_num_diffusion_timesteps, 1\n",
        "\n",
        "    poses_valid, poses_valid_2d, actions_valid, camerapara_valid = \\\n",
        "        fetch_me(subjects_test, dataset, keypoints, None, stride)\n",
        "    data_loader = valid_loader = data.DataLoader(\n",
        "        PoseGenerator_gmm(poses_valid, poses_valid_2d, actions_valid, camerapara_valid),\n",
        "        batch_size=batch_size, shuffle=False,\n",
        "        num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "\n",
        "    data_start = time.time()\n",
        "    data_time = 0\n",
        "\n",
        "    # Switch to test mode\n",
        "    torch.set_grad_enabled(False)\n",
        "    model_diff.eval()\n",
        "    model_pose.eval()\n",
        "\n",
        "    skip = test_num_diffusion_timesteps // test_timesteps\n",
        "    seq = range(0, test_num_diffusion_timesteps, skip)\n",
        "\n",
        "    epoch_loss_3d_pos = AverageMeter()\n",
        "    epoch_loss_3d_pos_procrustes = AverageMeter()\n",
        "    test_action_list = ['Directions','Discussion','Eating','Greeting','Phoning','Photo','Posing','Purchases','Sitting',\\\n",
        "        'SittingDown','Smoking','Waiting','WalkDog','Walking','WalkTogether']\n",
        "    action_error_sum = define_error_list(test_action_list)\n",
        "\n",
        "    for i, (_, input_noise_scale, input_2d, targets_3d, input_action, camera_para) in enumerate(data_loader):\n",
        "        data_time += time.time() - data_start\n",
        "\n",
        "        input_noise_scale, input_2d, targets_3d = \\\n",
        "            input_noise_scale.to(device), input_2d.to(device), targets_3d.to(device)\n",
        "\n",
        "        # build uvxyz\n",
        "        inputs_xyz = model_pose(input_2d, src_mask)\n",
        "        inputs_xyz[:, :, :] -= inputs_xyz[:, :1, :]\n",
        "        input_uvxyz = torch.cat([input_2d,inputs_xyz],dim=2)\n",
        "\n",
        "        # generate distribution\n",
        "        input_uvxyz = input_uvxyz.repeat(test_times,1,1)\n",
        "        input_noise_scale = input_noise_scale.repeat(test_times,1,1)\n",
        "        # select diffusion step\n",
        "        t = torch.ones(input_uvxyz.size(0)).type(torch.LongTensor).to(device)*test_num_diffusion_timesteps\n",
        "\n",
        "        # prepare the diffusion parameters\n",
        "        x = input_uvxyz.clone()\n",
        "        e = torch.randn_like(input_uvxyz)\n",
        "        b = betas\n",
        "        e = e*input_noise_scale\n",
        "        a = (1-b).cumprod(dim=0).index_select(0, t).view(-1, 1, 1)\n",
        "        # x = x * a.sqrt() + e * (1.0 - a).sqrt()\n",
        "\n",
        "        if edm:\n",
        "          output_uvxyz = generalized_steps_edm(x, src_mask, seq, model_diff, betas, eta=eta)\n",
        "        elif edm_1:\n",
        "          output_uvxyz = generalized_steps_edm1(x, src_mask, seq, model_diff, betas, eta=eta)\n",
        "        else:\n",
        "          output_uvxyz = generalized_steps(x, src_mask, seq, model_diff, betas, eta=eta)\n",
        "        output_uvxyz = output_uvxyz[0][-1]\n",
        "        output_uvxyz = torch.mean(output_uvxyz.reshape(test_times,-1,17,5),0)\n",
        "        output_xyz = output_uvxyz[:,:,2:]\n",
        "        output_xyz[:, :, :] -= output_xyz[:, :1, :]\n",
        "        targets_3d[:, :, :] -= targets_3d[:, :1, :]\n",
        "        epoch_loss_3d_pos.update(mpjpe(output_xyz, targets_3d).item() * 100.0, targets_3d.size(0))\n",
        "        epoch_loss_3d_pos_procrustes.update(p_mpjpe(output_xyz.cpu().numpy(), targets_3d.cpu().numpy()).item() * 100.0, targets_3d.size(0))\\\n",
        "\n",
        "        data_start = time.time()\n",
        "\n",
        "        action_error_sum = test_calculation(output_xyz, targets_3d, input_action, action_error_sum, None, None)\n",
        "\n",
        "        if i%100 == 0 and i != 0:\n",
        "            print('({batch}/{size}) Data: {data:.6f}s | MPJPE: {e1: .4f} | P-MPJPE: {e2: .4f}'\\\n",
        "                    .format(batch=i + 1, size=len(data_loader), data=data_time, e1=epoch_loss_3d_pos.avg,\\\n",
        "                        e2=epoch_loss_3d_pos_procrustes.avg))\n",
        "            print('sum ({batch}/{size}) Data: {data:.6f}s | MPJPE: {e1: .4f} | P-MPJPE: {e2: .4f}'\\\n",
        "            .format(batch=i + 1, size=len(data_loader), data=data_time, e1=epoch_loss_3d_pos.avg,\\\n",
        "                e2=epoch_loss_3d_pos_procrustes.avg))\n",
        "\n",
        "    p1, p2 = print_error(None, action_error_sum, is_train)\n",
        "\n",
        "    return p1, p2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1(linear beta schedule)"
      ],
      "metadata": {
        "id": "5Gs9keNmrj_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "loss_list_beta_1 = []\n",
        "p1_list_beta_1 = []\n",
        "p2_list_beta_1 = []\n",
        "'''"
      ],
      "metadata": {
        "id": "eNeFw03IeLNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "sLIFB9Aw94dw",
        "outputId": "76cfd123-6e9f-46ae-9910-d0de65e08454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Process Process-30:\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d4e3c372950>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-7519dcf8a017>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# predict noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moutput_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mloss_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moutput_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataParallel.forward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-a9cc385e7187>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask, t, cemd)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgconv_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matten_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgconv_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgconv_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-acf5ddc45b5d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-0b0c67e475b5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, sublayer)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msublayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-acf5ddc45b5d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-c9b21f74f74d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         Q, K, V = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n\u001b[0m\u001b[1;32m     19\u001b[0m                    for l, x in zip(self.linears, (query, key, value))]\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-c9b21f74f74d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         Q, K, V = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n\u001b[0m\u001b[1;32m     19\u001b[0m                    for l, x in zip(self.linears, (query, key, value))]\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "'''\n",
        "for epoch in range(start_epoch, n_epochs):\n",
        "    data_start = time.time()\n",
        "    data_time = 0\n",
        "\n",
        "    # Switch to train mode\n",
        "    torch.set_grad_enabled(True)\n",
        "    model_diff.train()\n",
        "\n",
        "    epoch_loss_diff = AverageMeter()\n",
        "\n",
        "    for i, (targets_uvxyz, targets_noise_scale, _, targets_3d, _, _) in enumerate(data_loader):\n",
        "        data_time += time.time() - data_start\n",
        "        step += 1\n",
        "\n",
        "        # to cuda\n",
        "        targets_uvxyz, targets_noise_scale, targets_3d = \\\n",
        "            targets_uvxyz.to(device), targets_noise_scale.to(device), targets_3d.to(device)\n",
        "\n",
        "        # generate nosiy sample based on seleted time t and beta\n",
        "        n = targets_3d.size(0)\n",
        "        x = targets_uvxyz\n",
        "        e = torch.randn_like(x)\n",
        "        b = betas_1\n",
        "        t = torch.randint(low=0, high=num_timesteps,\n",
        "                          size=(n // 2 + 1,)).to(device)\n",
        "        t = torch.cat([t, num_timesteps - t - 1], dim=0)[:n]\n",
        "        e = e*(targets_noise_scale)\n",
        "        a = (1-b).cumprod(dim=0).index_select(0, t).view(-1, 1, 1)\n",
        "        # generate x_t (refer to DDIM equation)\n",
        "        x = x * a.sqrt() + e * (1.0 - a).sqrt()\n",
        "\n",
        "        # predict noise\n",
        "        output_noise = model_diff(x, src_mask, t.float(), 0)\n",
        "        loss_diff = (e - output_noise).square().sum(dim=(1, 2)).mean(dim=0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_diff.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            model_diff.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss_diff.update(loss_diff.item(), n)\n",
        "\n",
        "        ema_helper.update(model_diff)\n",
        "\n",
        "        if i%100 == 0 and i != 0:\n",
        "            print('| Epoch{:0>4d}: {:0>4d}/{:0>4d} | Step {:0>6d} | Data: {:.6f} | Loss: {:.6f} |'\\\n",
        "                .format(epoch, i+1, len(data_loader), step, data_time, epoch_loss_diff.avg))\n",
        "\n",
        "    data_start = time.time()\n",
        "\n",
        "    if epoch % decay == 0:\n",
        "        lr_now = lr_decay(optimizer, epoch, lr_init, decay, gamma)\n",
        "\n",
        "\n",
        "\n",
        "    print('test the performance of current model')\n",
        "\n",
        "    p1, p2 = test_hyber(is_train=True)\n",
        "\n",
        "    if p1 < best_p1:\n",
        "        best_p1 = p1\n",
        "        best_epoch = epoch\n",
        "    print('| Best Epoch: {:0>4d} MPJPE: {:.2f} | Epoch: {:0>4d} MPJEPE: {:.2f} PA-MPJPE: {:.2f} |'\\\n",
        "        .format(best_epoch, best_p1, epoch, p1, p2))\n",
        "\n",
        "    loss_list_beta_1.append(epoch_loss_diff.avg)\n",
        "    p1_list_beta_1.append(p1)\n",
        "    p2_list_beta_1.append(p2)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "with open('loss1.txt', 'w') as file:\n",
        "    file.write('\\n'.join(str(l) for l in loss_list_beta_1))\n",
        "with open('p1_1.txt', 'w') as file:\n",
        "    file.write('\\n'.join(str(l) for l in p1_list_beta_1))\n",
        "with open('p2_1.txt', 'w') as file:\n",
        "    file.write('\\n'.join(str(l) for l in p2_list_beta_1))\n",
        "'''"
      ],
      "metadata": {
        "id": "YnhYxGCaoQOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2(cosine beta schedule)"
      ],
      "metadata": {
        "id": "HZ1dXdmrrcHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list_beta_2 = []\n",
        "p1_list_beta_2 = []\n",
        "p2_list_beta_2 = []"
      ],
      "metadata": {
        "id": "2npWSHs4nTo0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(start_epoch, n_epochs):\n",
        "    data_start = time.time()\n",
        "    data_time = 0\n",
        "\n",
        "    # Switch to train mode\n",
        "    torch.set_grad_enabled(True)\n",
        "    model_diff.train()\n",
        "\n",
        "    epoch_loss_diff = AverageMeter()\n",
        "\n",
        "    for i, (targets_uvxyz, targets_noise_scale, _, targets_3d, _, _) in enumerate(data_loader):\n",
        "        data_time += time.time() - data_start\n",
        "        step += 1\n",
        "\n",
        "        # to cuda\n",
        "        targets_uvxyz, targets_noise_scale, targets_3d = \\\n",
        "            targets_uvxyz.to(device), targets_noise_scale.to(device), targets_3d.to(device)\n",
        "\n",
        "        # generate nosiy sample based on seleted time t and beta\n",
        "        n = targets_3d.size(0)\n",
        "        x = targets_uvxyz\n",
        "        e = torch.randn_like(x)\n",
        "        b = betas_1\n",
        "        t = torch.randint(low=0, high=num_timesteps,\n",
        "                          size=(n // 2 + 1,)).to(device)\n",
        "        t = torch.cat([t, num_timesteps - t - 1], dim=0)[:n]\n",
        "        e = e*(targets_noise_scale)\n",
        "        a = (1-b).cumprod(dim=0).index_select(0, t).view(-1, 1, 1)\n",
        "        # generate x_t (refer to DDIM equation)\n",
        "        x = x * a.sqrt() + e * (1.0 - a).sqrt()\n",
        "\n",
        "        # predict noise\n",
        "        output_noise = model_diff(x, src_mask, t.float(), 0)\n",
        "        loss_diff = (e - output_noise).square().sum(dim=(1, 2)).mean(dim=0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_diff.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            model_diff.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss_diff.update(loss_diff.item(), n)\n",
        "\n",
        "        ema_helper.update(model_diff)\n",
        "\n",
        "        if i%100 == 0 and i != 0:\n",
        "            print('| Epoch{:0>4d}: {:0>4d}/{:0>4d} | Step {:0>6d} | Data: {:.6f} | Loss: {:.6f} |'\\\n",
        "                .format(epoch, i+1, len(data_loader), step, data_time, epoch_loss_diff.avg))\n",
        "\n",
        "    data_start = time.time()\n",
        "\n",
        "    if epoch % decay == 0:\n",
        "        lr_now = lr_decay(optimizer, epoch, lr_init, decay, gamma)\n",
        "\n",
        "\n",
        "\n",
        "    print('test the performance of current model')\n",
        "\n",
        "    p1, p2 = test_hyber(is_train=True)\n",
        "\n",
        "    if p1 < best_p1:\n",
        "        best_p1 = p1\n",
        "        best_epoch = epoch\n",
        "    print('| Best Epoch: {:0>4d} MPJPE: {:.2f} | Epoch: {:0>4d} MPJEPE: {:.2f} PA-MPJPE: {:.2f} |'\\\n",
        "        .format(best_epoch, best_p1, epoch, p1, p2))\n",
        "\n",
        "    loss_list_beta_2.append(epoch_loss_diff.avg)\n",
        "    p1_list_beta_2.append(p1)\n",
        "    p2_list_beta_2.append(p2)\n"
      ],
      "metadata": {
        "id": "gIcHiTYjmB6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95825bc8-84b7-40ea-eded-fa93e3e5e3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Epoch0000: 0101/1524 | Step 000101 | Data: 2055.982456 | Loss: 61.300082 |\n",
            "| Epoch0000: 0201/1524 | Step 000201 | Data: 5925.267459 | Loss: 52.932366 |\n",
            "| Epoch0000: 0301/1524 | Step 000301 | Data: 11616.311369 | Loss: 47.880242 |\n",
            "| Epoch0000: 0401/1524 | Step 000401 | Data: 19180.343270 | Loss: 44.329915 |\n",
            "| Epoch0000: 0501/1524 | Step 000501 | Data: 28575.217030 | Loss: 41.695045 |\n",
            "| Epoch0000: 0601/1524 | Step 000601 | Data: 39768.241064 | Loss: 39.659411 |\n",
            "| Epoch0000: 0701/1524 | Step 000701 | Data: 52749.220656 | Loss: 38.046888 |\n",
            "| Epoch0000: 0801/1524 | Step 000801 | Data: 67519.959991 | Loss: 36.734080 |\n",
            "| Epoch0000: 0901/1524 | Step 000901 | Data: 84096.649071 | Loss: 35.646042 |\n",
            "| Epoch0000: 1001/1524 | Step 001001 | Data: 102475.016578 | Loss: 34.709231 |\n",
            "| Epoch0000: 1101/1524 | Step 001101 | Data: 122656.485221 | Loss: 33.892972 |\n",
            "| Epoch0000: 1201/1524 | Step 001201 | Data: 144631.592710 | Loss: 33.176843 |\n",
            "| Epoch0000: 1301/1524 | Step 001301 | Data: 168454.569002 | Loss: 32.537140 |\n",
            "| Epoch0000: 1401/1524 | Step 001401 | Data: 194070.119537 | Loss: 31.959197 |\n",
            "| Epoch0000: 1501/1524 | Step 001501 | Data: 221418.149734 | Loss: 31.433359 |\n",
            "test the performance of current model\n",
            "Generating 543344 poses...\n",
            "(101/531) Data: 10.398404s | MPJPE:  48.2958 | P-MPJPE:  25.8084\n",
            "sum (101/531) Data: 10.398404s | MPJPE:  48.2958 | P-MPJPE:  25.8084\n",
            "(201/531) Data: 13.904572s | MPJPE:  48.2090 | P-MPJPE:  25.7764\n",
            "sum (201/531) Data: 13.904572s | MPJPE:  48.2090 | P-MPJPE:  25.7764\n",
            "(301/531) Data: 17.355601s | MPJPE:  47.5986 | P-MPJPE:  25.8066\n",
            "sum (301/531) Data: 17.355601s | MPJPE:  47.5986 | P-MPJPE:  25.8066\n",
            "(401/531) Data: 21.193253s | MPJPE:  47.8949 | P-MPJPE:  25.7173\n",
            "sum (401/531) Data: 21.193253s | MPJPE:  47.8949 | P-MPJPE:  25.7173\n",
            "(501/531) Data: 24.347562s | MPJPE:  47.4803 | P-MPJPE:  25.6522\n",
            "sum (501/531) Data: 24.347562s | MPJPE:  47.4803 | P-MPJPE:  25.6522\n",
            "| Best Epoch: 0000 MPJPE: 476.93 | Epoch: 0000 MPJEPE: 476.93 PA-MPJPE: 257.14 |\n",
            "| Epoch0001: 0101/1524 | Step 001625 | Data: 1820.629086 | Loss: 23.666083 |\n",
            "| Epoch0001: 0201/1524 | Step 001725 | Data: 5565.084150 | Loss: 23.524612 |\n",
            "| Epoch0001: 0301/1524 | Step 001825 | Data: 11140.254930 | Loss: 23.393607 |\n",
            "| Epoch0001: 0401/1524 | Step 001925 | Data: 18541.552385 | Loss: 23.276502 |\n",
            "| Epoch0001: 0501/1524 | Step 002025 | Data: 27710.979710 | Loss: 23.145289 |\n",
            "| Epoch0001: 0601/1524 | Step 002125 | Data: 38664.833910 | Loss: 23.027912 |\n",
            "| Epoch0001: 0701/1524 | Step 002225 | Data: 51390.605264 | Loss: 22.912981 |\n",
            "| Epoch0001: 0801/1524 | Step 002325 | Data: 65896.587172 | Loss: 22.802778 |\n",
            "| Epoch0001: 0901/1524 | Step 002425 | Data: 82158.035149 | Loss: 22.703839 |\n",
            "| Epoch0001: 1001/1524 | Step 002525 | Data: 100185.060305 | Loss: 22.608142 |\n",
            "| Epoch0001: 1101/1524 | Step 002625 | Data: 119984.559628 | Loss: 22.516436 |\n",
            "| Epoch0001: 1201/1524 | Step 002725 | Data: 141565.517232 | Loss: 22.431142 |\n",
            "| Epoch0001: 1301/1524 | Step 002825 | Data: 164996.724867 | Loss: 22.344214 |\n",
            "| Epoch0001: 1401/1524 | Step 002925 | Data: 190226.204243 | Loss: 22.265027 |\n",
            "| Epoch0001: 1501/1524 | Step 003025 | Data: 217155.155135 | Loss: 22.186456 |\n",
            "test the performance of current model\n",
            "Generating 543344 poses...\n",
            "(101/531) Data: 10.789203s | MPJPE:  48.0395 | P-MPJPE:  25.0600\n",
            "sum (101/531) Data: 10.789203s | MPJPE:  48.0395 | P-MPJPE:  25.0600\n",
            "(201/531) Data: 14.929553s | MPJPE:  47.9550 | P-MPJPE:  25.0574\n",
            "sum (201/531) Data: 14.929553s | MPJPE:  47.9550 | P-MPJPE:  25.0574\n",
            "(301/531) Data: 18.534086s | MPJPE:  47.3351 | P-MPJPE:  25.1063\n",
            "sum (301/531) Data: 18.534086s | MPJPE:  47.3351 | P-MPJPE:  25.1063\n",
            "(401/531) Data: 22.583504s | MPJPE:  47.6205 | P-MPJPE:  25.0063\n",
            "sum (401/531) Data: 22.583504s | MPJPE:  47.6205 | P-MPJPE:  25.0063\n",
            "(501/531) Data: 25.705487s | MPJPE:  47.2288 | P-MPJPE:  24.9511\n",
            "sum (501/531) Data: 25.705487s | MPJPE:  47.2288 | P-MPJPE:  24.9511\n",
            "| Best Epoch: 0001 MPJPE: 474.30 | Epoch: 0001 MPJEPE: 474.30 PA-MPJPE: 250.07 |\n",
            "| Epoch0002: 0101/1524 | Step 003149 | Data: 1992.791933 | Loss: 20.978058 |\n",
            "| Epoch0002: 0201/1524 | Step 003249 | Data: 6011.954746 | Loss: 20.932435 |\n",
            "| Epoch0002: 0301/1524 | Step 003349 | Data: 11905.989039 | Loss: 20.869269 |\n",
            "| Epoch0002: 0401/1524 | Step 003449 | Data: 19677.104489 | Loss: 20.810688 |\n",
            "| Epoch0002: 0501/1524 | Step 003549 | Data: 29304.619393 | Loss: 20.746865 |\n",
            "| Epoch0002: 0601/1524 | Step 003649 | Data: 40775.261699 | Loss: 20.688293 |\n",
            "| Epoch0002: 0701/1524 | Step 003749 | Data: 54088.723960 | Loss: 20.641389 |\n",
            "| Epoch0002: 0801/1524 | Step 003849 | Data: 69222.661803 | Loss: 20.589283 |\n",
            "| Epoch0002: 0901/1524 | Step 003949 | Data: 86200.725037 | Loss: 20.539726 |\n",
            "| Epoch0002: 1001/1524 | Step 004049 | Data: 104997.865808 | Loss: 20.489619 |\n",
            "| Epoch0002: 1101/1524 | Step 004149 | Data: 125643.878037 | Loss: 20.440264 |\n",
            "| Epoch0002: 1201/1524 | Step 004249 | Data: 148154.623477 | Loss: 20.392274 |\n",
            "| Epoch0002: 1301/1524 | Step 004349 | Data: 172523.438470 | Loss: 20.348566 |\n",
            "| Epoch0002: 1401/1524 | Step 004449 | Data: 198731.434100 | Loss: 20.302579 |\n",
            "| Epoch0002: 1501/1524 | Step 004549 | Data: 226738.879258 | Loss: 20.258192 |\n",
            "test the performance of current model\n",
            "Generating 543344 poses...\n",
            "(101/531) Data: 11.992983s | MPJPE:  47.1087 | P-MPJPE:  23.5070\n",
            "sum (101/531) Data: 11.992983s | MPJPE:  47.1087 | P-MPJPE:  23.5070\n",
            "(201/531) Data: 15.519071s | MPJPE:  47.0281 | P-MPJPE:  23.5653\n",
            "sum (201/531) Data: 15.519071s | MPJPE:  47.0281 | P-MPJPE:  23.5653\n",
            "(301/531) Data: 19.180760s | MPJPE:  46.4379 | P-MPJPE:  23.6292\n",
            "sum (301/531) Data: 19.180760s | MPJPE:  46.4379 | P-MPJPE:  23.6292\n",
            "(401/531) Data: 22.884325s | MPJPE:  46.7129 | P-MPJPE:  23.5391\n",
            "sum (401/531) Data: 22.884325s | MPJPE:  46.7129 | P-MPJPE:  23.5391\n",
            "(501/531) Data: 25.805615s | MPJPE:  46.3471 | P-MPJPE:  23.4862\n",
            "sum (501/531) Data: 25.805615s | MPJPE:  46.3471 | P-MPJPE:  23.4862\n",
            "| Best Epoch: 0002 MPJPE: 465.39 | Epoch: 0002 MPJEPE: 465.39 PA-MPJPE: 235.35 |\n",
            "| Epoch0003: 0101/1524 | Step 004673 | Data: 1976.579114 | Loss: 19.537701 |\n",
            "| Epoch0003: 0201/1524 | Step 004773 | Data: 6003.359668 | Loss: 19.494733 |\n",
            "| Epoch0003: 0301/1524 | Step 004873 | Data: 11952.771590 | Loss: 19.459319 |\n",
            "| Epoch0003: 0401/1524 | Step 004973 | Data: 19778.780562 | Loss: 19.423533 |\n",
            "| Epoch0003: 0501/1524 | Step 005073 | Data: 29436.794940 | Loss: 19.381005 |\n",
            "| Epoch0003: 0601/1524 | Step 005173 | Data: 40937.404335 | Loss: 19.342334 |\n",
            "| Epoch0003: 0701/1524 | Step 005273 | Data: 54267.318040 | Loss: 19.297803 |\n",
            "| Epoch0003: 0801/1524 | Step 005373 | Data: 69439.393395 | Loss: 19.262938 |\n",
            "| Epoch0003: 0901/1524 | Step 005473 | Data: 86430.130612 | Loss: 19.220420 |\n",
            "| Epoch0003: 1001/1524 | Step 005573 | Data: 105253.925106 | Loss: 19.179643 |\n",
            "| Epoch0003: 1101/1524 | Step 005673 | Data: 125926.160564 | Loss: 19.139288 |\n",
            "| Epoch0003: 1201/1524 | Step 005773 | Data: 148393.620713 | Loss: 19.100900 |\n",
            "| Epoch0003: 1301/1524 | Step 005873 | Data: 172678.341336 | Loss: 19.060562 |\n",
            "| Epoch0003: 1401/1524 | Step 005973 | Data: 198783.304034 | Loss: 19.023529 |\n",
            "| Epoch0003: 1501/1524 | Step 006073 | Data: 226602.832225 | Loss: 18.984027 |\n",
            "test the performance of current model\n",
            "Generating 543344 poses...\n",
            "(101/531) Data: 11.475206s | MPJPE:  45.9002 | P-MPJPE:  22.3873\n",
            "sum (101/531) Data: 11.475206s | MPJPE:  45.9002 | P-MPJPE:  22.3873\n",
            "(201/531) Data: 15.428808s | MPJPE:  45.8261 | P-MPJPE:  22.4514\n",
            "sum (201/531) Data: 15.428808s | MPJPE:  45.8261 | P-MPJPE:  22.4514\n",
            "(301/531) Data: 19.155456s | MPJPE:  45.2781 | P-MPJPE:  22.5099\n",
            "sum (301/531) Data: 19.155456s | MPJPE:  45.2781 | P-MPJPE:  22.5099\n",
            "(401/531) Data: 23.129157s | MPJPE:  45.5361 | P-MPJPE:  22.3905\n",
            "sum (401/531) Data: 23.129157s | MPJPE:  45.5361 | P-MPJPE:  22.3905\n",
            "(501/531) Data: 26.330566s | MPJPE:  45.1896 | P-MPJPE:  22.3224\n",
            "sum (501/531) Data: 26.330566s | MPJPE:  45.1896 | P-MPJPE:  22.3224\n",
            "| Best Epoch: 0003 MPJPE: 453.70 | Epoch: 0003 MPJEPE: 453.70 PA-MPJPE: 223.56 |\n",
            "| Epoch0004: 0101/1524 | Step 006197 | Data: 2026.145696 | Loss: 18.345616 |\n",
            "| Epoch0004: 0201/1524 | Step 006297 | Data: 6232.587330 | Loss: 18.312237 |\n",
            "| Epoch0004: 0301/1524 | Step 006397 | Data: 12355.705595 | Loss: 18.268645 |\n",
            "| Epoch0004: 0401/1524 | Step 006497 | Data: 20400.523467 | Loss: 18.224799 |\n",
            "| Epoch0004: 0501/1524 | Step 006597 | Data: 30363.867095 | Loss: 18.188275 |\n",
            "| Epoch0004: 0601/1524 | Step 006697 | Data: 42220.504774 | Loss: 18.144657 |\n",
            "| Epoch0004: 0701/1524 | Step 006797 | Data: 55956.272539 | Loss: 18.105633 |\n",
            "| Epoch0004: 0801/1524 | Step 006897 | Data: 71591.107459 | Loss: 18.070608 |\n",
            "| Epoch0004: 0901/1524 | Step 006997 | Data: 89138.445078 | Loss: 18.032416 |\n",
            "| Epoch0004: 1001/1524 | Step 007097 | Data: 108561.387867 | Loss: 17.996776 |\n",
            "| Epoch0004: 1101/1524 | Step 007197 | Data: 129922.215592 | Loss: 17.962379 |\n",
            "| Epoch0004: 1201/1524 | Step 007297 | Data: 153211.209439 | Loss: 17.921419 |\n",
            "| Epoch0004: 1301/1524 | Step 007397 | Data: 178379.251251 | Loss: 17.885163 |\n",
            "| Epoch0004: 1401/1524 | Step 007497 | Data: 205452.615543 | Loss: 17.848570 |\n",
            "| Epoch0004: 1501/1524 | Step 007597 | Data: 234332.090308 | Loss: 17.813148 |\n",
            "test the performance of current model\n",
            "Generating 543344 poses...\n",
            "(101/531) Data: 10.880426s | MPJPE:  44.5217 | P-MPJPE:  21.2728\n",
            "sum (101/531) Data: 10.880426s | MPJPE:  44.5217 | P-MPJPE:  21.2728\n",
            "(201/531) Data: 14.812085s | MPJPE:  44.4325 | P-MPJPE:  21.3359\n",
            "sum (201/531) Data: 14.812085s | MPJPE:  44.4325 | P-MPJPE:  21.3359\n",
            "(301/531) Data: 18.118855s | MPJPE:  43.9094 | P-MPJPE:  21.3830\n",
            "sum (301/531) Data: 18.118855s | MPJPE:  43.9094 | P-MPJPE:  21.3830\n",
            "(401/531) Data: 22.075294s | MPJPE:  44.1615 | P-MPJPE:  21.2812\n",
            "sum (401/531) Data: 22.075294s | MPJPE:  44.1615 | P-MPJPE:  21.2812\n",
            "(501/531) Data: 25.324850s | MPJPE:  43.8107 | P-MPJPE:  21.2129\n",
            "sum (501/531) Data: 25.324850s | MPJPE:  43.8107 | P-MPJPE:  21.2129\n",
            "| Best Epoch: 0004 MPJPE: 439.98 | Epoch: 0004 MPJEPE: 439.98 PA-MPJPE: 212.32 |\n",
            "| Epoch0005: 0101/1524 | Step 007721 | Data: 1916.810442 | Loss: 17.187160 |\n",
            "| Epoch0005: 0201/1524 | Step 007821 | Data: 5767.279931 | Loss: 17.167086 |\n",
            "| Epoch0005: 0301/1524 | Step 007921 | Data: 11382.851161 | Loss: 17.152203 |\n",
            "| Epoch0005: 0401/1524 | Step 008021 | Data: 18765.287896 | Loss: 17.111275 |\n",
            "| Epoch0005: 0501/1524 | Step 008121 | Data: 27902.751892 | Loss: 17.077085 |\n",
            "| Epoch0005: 0601/1524 | Step 008221 | Data: 38817.297498 | Loss: 17.049049 |\n",
            "| Epoch0005: 0701/1524 | Step 008321 | Data: 51580.208610 | Loss: 17.015861 |\n",
            "| Epoch0005: 0801/1524 | Step 008421 | Data: 66193.458098 | Loss: 16.981640 |\n",
            "| Epoch0005: 0901/1524 | Step 008521 | Data: 82644.203189 | Loss: 16.939474 |\n",
            "| Epoch0005: 1001/1524 | Step 008621 | Data: 100959.061599 | Loss: 16.910585 |\n",
            "| Epoch0005: 1101/1524 | Step 008721 | Data: 121170.115608 | Loss: 16.881201 |\n",
            "| Epoch0005: 1201/1524 | Step 008821 | Data: 143220.216872 | Loss: 16.850888 |\n",
            "| Epoch0005: 1301/1524 | Step 008921 | Data: 167103.163244 | Loss: 16.818225 |\n",
            "| Epoch0005: 1401/1524 | Step 009021 | Data: 192835.661479 | Loss: 16.785461 |\n",
            "| Epoch0005: 1501/1524 | Step 009121 | Data: 220325.729830 | Loss: 16.752141 |\n",
            "test the performance of current model\n",
            "Generating 543344 poses...\n",
            "(101/531) Data: 12.799041s | MPJPE:  43.3737 | P-MPJPE:  20.8814\n",
            "sum (101/531) Data: 12.799041s | MPJPE:  43.3737 | P-MPJPE:  20.8814\n",
            "(201/531) Data: 16.238957s | MPJPE:  43.2767 | P-MPJPE:  20.9406\n",
            "sum (201/531) Data: 16.238957s | MPJPE:  43.2767 | P-MPJPE:  20.9406\n",
            "(301/531) Data: 19.736259s | MPJPE:  42.7641 | P-MPJPE:  20.9559\n",
            "sum (301/531) Data: 19.736259s | MPJPE:  42.7641 | P-MPJPE:  20.9559\n",
            "(401/531) Data: 23.558988s | MPJPE:  43.0115 | P-MPJPE:  20.8804\n",
            "sum (401/531) Data: 23.558988s | MPJPE:  43.0115 | P-MPJPE:  20.8804\n",
            "(501/531) Data: 26.624833s | MPJPE:  42.6481 | P-MPJPE:  20.8008\n",
            "sum (501/531) Data: 26.624833s | MPJPE:  42.6481 | P-MPJPE:  20.8008\n",
            "| Best Epoch: 0005 MPJPE: 428.40 | Epoch: 0005 MPJEPE: 428.40 PA-MPJPE: 208.15 |\n",
            "| Epoch0006: 0101/1524 | Step 009245 | Data: 2048.130216 | Loss: 16.226861 |\n",
            "| Epoch0006: 0201/1524 | Step 009345 | Data: 6098.725262 | Loss: 16.191697 |\n",
            "| Epoch0006: 0301/1524 | Step 009445 | Data: 11982.179727 | Loss: 16.166777 |\n",
            "| Epoch0006: 0401/1524 | Step 009545 | Data: 19700.933038 | Loss: 16.135948 |\n",
            "| Epoch0006: 0501/1524 | Step 009645 | Data: 29236.262447 | Loss: 16.110569 |\n",
            "| Epoch0006: 0601/1524 | Step 009745 | Data: 40615.889697 | Loss: 16.083081 |\n",
            "| Epoch0006: 0701/1524 | Step 009845 | Data: 53793.694133 | Loss: 16.050589 |\n",
            "| Epoch0006: 0801/1524 | Step 009945 | Data: 68709.283614 | Loss: 16.019495 |\n",
            "| Epoch0006: 0901/1524 | Step 010045 | Data: 85332.591115 | Loss: 15.989131 |\n",
            "| Epoch0006: 1001/1524 | Step 010145 | Data: 103703.278993 | Loss: 15.960171 |\n",
            "| Epoch0006: 1101/1524 | Step 010245 | Data: 123850.141838 | Loss: 15.928017 |\n",
            "| Epoch0006: 1201/1524 | Step 010345 | Data: 145738.015672 | Loss: 15.899319 |\n",
            "| Epoch0006: 1301/1524 | Step 010445 | Data: 169364.269173 | Loss: 15.870248 |\n",
            "| Epoch0006: 1401/1524 | Step 010545 | Data: 194714.042529 | Loss: 15.844365 |\n",
            "| Epoch0006: 1501/1524 | Step 010645 | Data: 221715.379226 | Loss: 15.815099 |\n",
            "test the performance of current model\n",
            "Generating 543344 poses...\n",
            "(101/531) Data: 10.831895s | MPJPE:  42.4151 | P-MPJPE:  20.7489\n",
            "sum (101/531) Data: 10.831895s | MPJPE:  42.4151 | P-MPJPE:  20.7489\n",
            "(201/531) Data: 14.405587s | MPJPE:  42.3113 | P-MPJPE:  20.7956\n",
            "sum (201/531) Data: 14.405587s | MPJPE:  42.3113 | P-MPJPE:  20.7956\n",
            "(301/531) Data: 17.525218s | MPJPE:  41.7952 | P-MPJPE:  20.7634\n",
            "sum (301/531) Data: 17.525218s | MPJPE:  41.7952 | P-MPJPE:  20.7634\n",
            "(401/531) Data: 21.214871s | MPJPE:  42.0357 | P-MPJPE:  20.6921\n",
            "sum (401/531) Data: 21.214871s | MPJPE:  42.0357 | P-MPJPE:  20.6921\n",
            "(501/531) Data: 24.282457s | MPJPE:  41.6523 | P-MPJPE:  20.5777\n",
            "sum (501/531) Data: 24.282457s | MPJPE:  41.6523 | P-MPJPE:  20.5777\n",
            "| Best Epoch: 0006 MPJPE: 418.49 | Epoch: 0006 MPJEPE: 418.49 PA-MPJPE: 206.02 |\n",
            "| Epoch0007: 0101/1524 | Step 010769 | Data: 2025.601613 | Loss: 15.361754 |\n",
            "| Epoch0007: 0201/1524 | Step 010869 | Data: 5867.501366 | Loss: 15.337894 |\n",
            "| Epoch0007: 0301/1524 | Step 010969 | Data: 11465.101303 | Loss: 15.306566 |\n",
            "| Epoch0007: 0401/1524 | Step 011069 | Data: 18833.554673 | Loss: 15.286882 |\n",
            "| Epoch0007: 0501/1524 | Step 011169 | Data: 27943.093451 | Loss: 15.261008 |\n",
            "| Epoch0007: 0601/1524 | Step 011269 | Data: 38803.551921 | Loss: 15.241224 |\n",
            "| Epoch0007: 0701/1524 | Step 011369 | Data: 51406.308024 | Loss: 15.216803 |\n",
            "| Epoch0007: 0801/1524 | Step 011469 | Data: 65751.581818 | Loss: 15.194467 |\n",
            "| Epoch0007: 0901/1524 | Step 011569 | Data: 81836.980603 | Loss: 15.173986 |\n",
            "| Epoch0007: 1001/1524 | Step 011669 | Data: 99660.264019 | Loss: 15.150811 |\n",
            "| Epoch0007: 1101/1524 | Step 011769 | Data: 119251.811591 | Loss: 15.128413 |\n",
            "| Epoch0007: 1201/1524 | Step 011869 | Data: 140579.434929 | Loss: 15.109595 |\n",
            "| Epoch0007: 1301/1524 | Step 011969 | Data: 163636.253539 | Loss: 15.090820 |\n",
            "| Epoch0007: 1401/1524 | Step 012069 | Data: 188455.994962 | Loss: 15.070208 |\n",
            "| Epoch0007: 1501/1524 | Step 012169 | Data: 214940.489483 | Loss: 15.046880 |\n",
            "test the performance of current model\n",
            "Generating 543344 poses...\n",
            "(101/531) Data: 12.349227s | MPJPE:  41.7771 | P-MPJPE:  20.5629\n",
            "sum (101/531) Data: 12.349227s | MPJPE:  41.7771 | P-MPJPE:  20.5629\n",
            "(201/531) Data: 15.967932s | MPJPE:  41.6690 | P-MPJPE:  20.5974\n",
            "sum (201/531) Data: 15.967932s | MPJPE:  41.6690 | P-MPJPE:  20.5974\n",
            "(301/531) Data: 19.089679s | MPJPE:  41.1460 | P-MPJPE:  20.5330\n",
            "sum (301/531) Data: 19.089679s | MPJPE:  41.1460 | P-MPJPE:  20.5330\n",
            "(401/531) Data: 22.886145s | MPJPE:  41.3825 | P-MPJPE:  20.4680\n",
            "sum (401/531) Data: 22.886145s | MPJPE:  41.3825 | P-MPJPE:  20.4680\n",
            "(501/531) Data: 25.753013s | MPJPE:  40.9850 | P-MPJPE:  20.3224\n",
            "sum (501/531) Data: 25.753013s | MPJPE:  40.9850 | P-MPJPE:  20.3224\n",
            "| Best Epoch: 0007 MPJPE: 411.84 | Epoch: 0007 MPJEPE: 411.84 PA-MPJPE: 203.59 |\n",
            "| Epoch0008: 0101/1524 | Step 012293 | Data: 1822.762040 | Loss: 14.707187 |\n",
            "| Epoch0008: 0201/1524 | Step 012393 | Data: 5532.611962 | Loss: 14.686071 |\n",
            "| Epoch0008: 0301/1524 | Step 012493 | Data: 10967.899037 | Loss: 14.661141 |\n",
            "| Epoch0008: 0401/1524 | Step 012593 | Data: 18145.775808 | Loss: 14.655504 |\n",
            "| Epoch0008: 0501/1524 | Step 012693 | Data: 27038.161949 | Loss: 14.632514 |\n",
            "| Epoch0008: 0601/1524 | Step 012793 | Data: 37683.499322 | Loss: 14.617023 |\n",
            "| Epoch0008: 0701/1524 | Step 012893 | Data: 50051.927918 | Loss: 14.598137 |\n",
            "| Epoch0008: 0801/1524 | Step 012993 | Data: 64162.025023 | Loss: 14.579146 |\n",
            "| Epoch0008: 0901/1524 | Step 013093 | Data: 80011.551407 | Loss: 14.569324 |\n",
            "| Epoch0008: 1001/1524 | Step 013193 | Data: 97602.163161 | Loss: 14.555501 |\n",
            "| Epoch0008: 1101/1524 | Step 013293 | Data: 116936.738646 | Loss: 14.537643 |\n",
            "| Epoch0008: 1201/1524 | Step 013393 | Data: 138040.938755 | Loss: 14.523074 |\n",
            "| Epoch0008: 1301/1524 | Step 013493 | Data: 160974.354194 | Loss: 14.505507 |\n",
            "| Epoch0008: 1401/1524 | Step 013593 | Data: 185680.828371 | Loss: 14.489749 |\n",
            "| Epoch0008: 1501/1524 | Step 013693 | Data: 212045.796523 | Loss: 14.472055 |\n",
            "test the performance of current model\n",
            "Generating 543344 poses...\n",
            "(101/531) Data: 10.778349s | MPJPE:  41.4388 | P-MPJPE:  20.4346\n",
            "sum (101/531) Data: 10.778349s | MPJPE:  41.4388 | P-MPJPE:  20.4346\n",
            "(201/531) Data: 14.360383s | MPJPE:  41.3369 | P-MPJPE:  20.4763\n",
            "sum (201/531) Data: 14.360383s | MPJPE:  41.3369 | P-MPJPE:  20.4763\n",
            "(301/531) Data: 17.602043s | MPJPE:  40.8037 | P-MPJPE:  20.4029\n",
            "sum (301/531) Data: 17.602043s | MPJPE:  40.8037 | P-MPJPE:  20.4029\n",
            "(401/531) Data: 21.303977s | MPJPE:  41.0367 | P-MPJPE:  20.3342\n",
            "sum (401/531) Data: 21.303977s | MPJPE:  41.0367 | P-MPJPE:  20.3342\n",
            "(501/531) Data: 24.068017s | MPJPE:  40.6273 | P-MPJPE:  20.1688\n",
            "sum (501/531) Data: 24.068017s | MPJPE:  40.6273 | P-MPJPE:  20.1688\n",
            "| Best Epoch: 0008 MPJPE: 408.25 | Epoch: 0008 MPJEPE: 408.25 PA-MPJPE: 202.06 |\n",
            "| Epoch0009: 0101/1524 | Step 013817 | Data: 1854.419894 | Loss: 14.198060 |\n",
            "| Epoch0009: 0201/1524 | Step 013917 | Data: 5537.725819 | Loss: 14.177298 |\n",
            "| Epoch0009: 0301/1524 | Step 014017 | Data: 10948.596226 | Loss: 14.166838 |\n",
            "| Epoch0009: 0401/1524 | Step 014117 | Data: 18092.922575 | Loss: 14.162297 |\n",
            "| Epoch0009: 0501/1524 | Step 014217 | Data: 26969.970311 | Loss: 14.134810 |\n",
            "| Epoch0009: 0601/1524 | Step 014317 | Data: 37580.698905 | Loss: 14.122711 |\n",
            "| Epoch0009: 0701/1524 | Step 014417 | Data: 49934.127177 | Loss: 14.115990 |\n",
            "| Epoch0009: 0801/1524 | Step 014517 | Data: 64031.753757 | Loss: 14.102019 |\n",
            "| Epoch0009: 0901/1524 | Step 014617 | Data: 79897.996680 | Loss: 14.091262 |\n",
            "| Epoch0009: 1001/1524 | Step 014717 | Data: 97498.193263 | Loss: 14.079368 |\n",
            "| Epoch0009: 1101/1524 | Step 014817 | Data: 116832.849157 | Loss: 14.065851 |\n",
            "| Epoch0009: 1201/1524 | Step 014917 | Data: 137959.642276 | Loss: 14.054064 |\n",
            "| Epoch0009: 1301/1524 | Step 015017 | Data: 160846.672492 | Loss: 14.042557 |\n",
            "| Epoch0009: 1401/1524 | Step 015117 | Data: 185479.375787 | Loss: 14.031083 |\n",
            "| Epoch0009: 1501/1524 | Step 015217 | Data: 211764.180999 | Loss: 14.016815 |\n",
            "test the performance of current model\n",
            "Generating 543344 poses...\n",
            "(101/531) Data: 11.457432s | MPJPE:  41.1293 | P-MPJPE:  20.2122\n",
            "sum (101/531) Data: 11.457432s | MPJPE:  41.1293 | P-MPJPE:  20.2122\n",
            "(201/531) Data: 15.102793s | MPJPE:  41.0365 | P-MPJPE:  20.2631\n",
            "sum (201/531) Data: 15.102793s | MPJPE:  41.0365 | P-MPJPE:  20.2631\n",
            "(301/531) Data: 18.406024s | MPJPE:  40.4997 | P-MPJPE:  20.1895\n",
            "sum (301/531) Data: 18.406024s | MPJPE:  40.4997 | P-MPJPE:  20.1895\n",
            "(401/531) Data: 22.125514s | MPJPE:  40.7357 | P-MPJPE:  20.1178\n",
            "sum (401/531) Data: 22.125514s | MPJPE:  40.7357 | P-MPJPE:  20.1178\n",
            "(501/531) Data: 25.061626s | MPJPE:  40.3174 | P-MPJPE:  19.9429\n",
            "sum (501/531) Data: 25.061626s | MPJPE:  40.3174 | P-MPJPE:  19.9429\n",
            "| Best Epoch: 0009 MPJPE: 405.15 | Epoch: 0009 MPJEPE: 405.15 PA-MPJPE: 199.83 |\n",
            "| Epoch0010: 0101/1524 | Step 015341 | Data: 1880.718838 | Loss: 13.770200 |\n",
            "| Epoch0010: 0201/1524 | Step 015441 | Data: 5672.867352 | Loss: 13.801883 |\n",
            "| Epoch0010: 0301/1524 | Step 015541 | Data: 11208.629587 | Loss: 13.797937 |\n",
            "| Epoch0010: 0401/1524 | Step 015641 | Data: 18564.799037 | Loss: 13.791577 |\n",
            "| Epoch0010: 0501/1524 | Step 015741 | Data: 27692.515528 | Loss: 13.774290 |\n",
            "| Epoch0010: 0601/1524 | Step 015841 | Data: 38609.595514 | Loss: 13.759575 |\n",
            "| Epoch0010: 0701/1524 | Step 015941 | Data: 51319.556411 | Loss: 13.752287 |\n",
            "| Epoch0010: 0801/1524 | Step 016041 | Data: 65811.571960 | Loss: 13.736641 |\n",
            "| Epoch0010: 0901/1524 | Step 016141 | Data: 82099.277472 | Loss: 13.726910 |\n",
            "| Epoch0010: 1001/1524 | Step 016241 | Data: 100172.943461 | Loss: 13.717011 |\n",
            "| Epoch0010: 1101/1524 | Step 016341 | Data: 120076.078528 | Loss: 13.705961 |\n",
            "| Epoch0010: 1201/1524 | Step 016441 | Data: 141812.908600 | Loss: 13.693003 |\n",
            "| Epoch0010: 1301/1524 | Step 016541 | Data: 165347.531444 | Loss: 13.682767 |\n",
            "| Epoch0010: 1401/1524 | Step 016641 | Data: 190664.639904 | Loss: 13.670642 |\n",
            "| Epoch0010: 1501/1524 | Step 016741 | Data: 217727.525364 | Loss: 13.659545 |\n",
            "test the performance of current model\n",
            "Generating 543344 poses...\n",
            "(101/531) Data: 10.511690s | MPJPE:  41.0372 | P-MPJPE:  20.3038\n",
            "sum (101/531) Data: 10.511690s | MPJPE:  41.0372 | P-MPJPE:  20.3038\n",
            "(201/531) Data: 13.924563s | MPJPE:  40.9453 | P-MPJPE:  20.3503\n",
            "sum (201/531) Data: 13.924563s | MPJPE:  40.9453 | P-MPJPE:  20.3503\n",
            "(301/531) Data: 17.039485s | MPJPE:  40.4062 | P-MPJPE:  20.2595\n",
            "sum (301/531) Data: 17.039485s | MPJPE:  40.4062 | P-MPJPE:  20.2595\n",
            "(401/531) Data: 20.968128s | MPJPE:  40.6477 | P-MPJPE:  20.1964\n",
            "sum (401/531) Data: 20.968128s | MPJPE:  40.6477 | P-MPJPE:  20.1964\n",
            "(501/531) Data: 24.142300s | MPJPE:  40.2243 | P-MPJPE:  20.0023\n",
            "sum (501/531) Data: 24.142300s | MPJPE:  40.2243 | P-MPJPE:  20.0023\n",
            "| Best Epoch: 0010 MPJPE: 404.22 | Epoch: 0010 MPJEPE: 404.22 PA-MPJPE: 200.53 |\n",
            "| Epoch0011: 0101/1524 | Step 016865 | Data: 1902.278035 | Loss: 13.501905 |\n",
            "| Epoch0011: 0201/1524 | Step 016965 | Data: 5688.095174 | Loss: 13.472945 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('loss2.txt', 'w') as file:\n",
        "    file.write('\\n'.join(str(l) for l in loss_list_beta_2))\n",
        "with open('p1_2.txt', 'w') as file:\n",
        "    file.write('\\n'.join(str(l) for l in p1_list_beta_2))\n",
        "with open('p2_2.txt', 'w') as file:\n",
        "    file.write('\\n'.join(str(l) for l in p2_list_beta_2))"
      ],
      "metadata": {
        "id": "d9xf33dEqXoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3(Use edm to replace DDIM)"
      ],
      "metadata": {
        "id": "KTJMLzNOLHmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "loss_list_beta_1_edm = []\n",
        "p1_list_beta_1_edm = []\n",
        "p2_list_beta_1_edm = []\n",
        "'''"
      ],
      "metadata": {
        "id": "Pe6702GcK-x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for epoch in range(start_epoch, n_epochs):\n",
        "    data_start = time.time()\n",
        "    data_time = 0\n",
        "\n",
        "    # Switch to train mode\n",
        "    torch.set_grad_enabled(True)\n",
        "    model_diff.train()\n",
        "\n",
        "    epoch_loss_diff = AverageMeter()\n",
        "\n",
        "    for i, (targets_uvxyz, targets_noise_scale, _, targets_3d, _, _) in enumerate(data_loader):\n",
        "        data_time += time.time() - data_start\n",
        "        step += 1\n",
        "\n",
        "        # to cuda\n",
        "        targets_uvxyz, targets_noise_scale, targets_3d = \\\n",
        "            targets_uvxyz.to(device), targets_noise_scale.to(device), targets_3d.to(device)\n",
        "\n",
        "        # generate nosiy sample based on seleted time t and beta\n",
        "        n = targets_3d.size(0)\n",
        "        x = targets_uvxyz\n",
        "        e = torch.randn_like(x)\n",
        "        b = betas_1\n",
        "        t = torch.randint(low=0, high=num_timesteps,\n",
        "                          size=(n // 2 + 1,)).to(device)\n",
        "        t = torch.cat([t, num_timesteps - t - 1], dim=0)[:n]\n",
        "        e = e*(targets_noise_scale)\n",
        "        a = (1-b).cumprod(dim=0).index_select(0, t).view(-1, 1, 1)\n",
        "        # generate x_t (refer to DDIM equation)\n",
        "        x = x * a.sqrt() + e * (1.0 - a).sqrt()\n",
        "\n",
        "        # predict noise\n",
        "        output_noise = model_diff(x, src_mask, t.float(), 0)\n",
        "        loss_diff = (e - output_noise).square().sum(dim=(1, 2)).mean(dim=0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_diff.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            model_diff.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss_diff.update(loss_diff.item(), n)\n",
        "\n",
        "        ema_helper.update(model_diff)\n",
        "\n",
        "        if i%100 == 0 and i != 0:\n",
        "            print('| Epoch{:0>4d}: {:0>4d}/{:0>4d} | Step {:0>6d} | Data: {:.6f} | Loss: {:.6f} |'\\\n",
        "                .format(epoch, i+1, len(data_loader), step, data_time, epoch_loss_diff.avg))\n",
        "\n",
        "    data_start = time.time()\n",
        "\n",
        "    if epoch % decay == 0:\n",
        "        lr_now = lr_decay(optimizer, epoch, lr_init, decay, gamma)\n",
        "\n",
        "\n",
        "\n",
        "    print('test the performance of current model')\n",
        "\n",
        "    p1, p2 = test_hyber(edm=True, is_train=True)\n",
        "\n",
        "    if p1 < best_p1:\n",
        "        best_p1 = p1\n",
        "        best_epoch = epoch\n",
        "    print('| Best Epoch: {:0>4d} MPJPE: {:.2f} | Epoch: {:0>4d} MPJEPE: {:.2f} PA-MPJPE: {:.2f} |'\\\n",
        "        .format(best_epoch, best_p1, epoch, p1, p2))\n",
        "\n",
        "    loss_list_beta_2.append(epoch_loss_diff.avg)\n",
        "    p1_list_beta_2.append(p1)\n",
        "    p2_list_beta_2.append(p2)\n",
        "'''"
      ],
      "metadata": {
        "id": "4EHNQWgALMzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "with open('loss3.txt', 'w') as file:\n",
        "    file.write('\\n'.join(str(l) for l in loss_list_beta_1_edm))\n",
        "with open('p1_3.txt', 'w') as file:\n",
        "    file.write('\\n'.join(str(l) for l in p1_list_beta_1_edm))\n",
        "with open('p2_3.txt', 'w') as file:\n",
        "    file.write('\\n'.join(str(l) for l in p2_list_beta_1_edm))\n",
        "'''"
      ],
      "metadata": {
        "id": "ZTsNunhYMn5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4(Use edm to replace DDIM substitute test, not recorded)"
      ],
      "metadata": {
        "id": "QVbcVz4eMyIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "loss_list_beta_1_edm1 = []\n",
        "p1_list_beta_1_edm1 = []\n",
        "p2_list_beta_1_edm1 = []\n",
        "'''"
      ],
      "metadata": {
        "id": "I5aAeaNdM0Ri"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for epoch in range(start_epoch, n_epochs):\n",
        "    data_start = time.time()\n",
        "    data_time = 0\n",
        "\n",
        "    # Switch to train mode\n",
        "    torch.set_grad_enabled(True)\n",
        "    model_diff.train()\n",
        "\n",
        "    epoch_loss_diff = AverageMeter()\n",
        "\n",
        "    for i, (targets_uvxyz, targets_noise_scale, _, targets_3d, _, _) in enumerate(data_loader):\n",
        "        data_time += time.time() - data_start\n",
        "        step += 1\n",
        "\n",
        "        # to cuda\n",
        "        targets_uvxyz, targets_noise_scale, targets_3d = \\\n",
        "            targets_uvxyz.to(device), targets_noise_scale.to(device), targets_3d.to(device)\n",
        "\n",
        "        # generate nosiy sample based on seleted time t and beta\n",
        "        n = targets_3d.size(0)\n",
        "        x = targets_uvxyz\n",
        "        e = torch.randn_like(x)\n",
        "        b = betas_1\n",
        "        t = torch.randint(low=0, high=num_timesteps,\n",
        "                          size=(n // 2 + 1,)).to(device)\n",
        "        t = torch.cat([t, num_timesteps - t - 1], dim=0)[:n]\n",
        "        e = e*(targets_noise_scale)\n",
        "        a = (1-b).cumprod(dim=0).index_select(0, t).view(-1, 1, 1)\n",
        "        # generate x_t (refer to DDIM equation)\n",
        "        x = x * a.sqrt() + e * (1.0 - a).sqrt()\n",
        "\n",
        "        # predict noise\n",
        "        output_noise = model_diff(x, src_mask, t.float(), 0)\n",
        "        loss_diff = (e - output_noise).square().sum(dim=(1, 2)).mean(dim=0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_diff.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            model_diff.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss_diff.update(loss_diff.item(), n)\n",
        "\n",
        "        ema_helper.update(model_diff)\n",
        "\n",
        "        if i%100 == 0 and i != 0:\n",
        "            print('| Epoch{:0>4d}: {:0>4d}/{:0>4d} | Step {:0>6d} | Data: {:.6f} | Loss: {:.6f} |'\\\n",
        "                .format(epoch, i+1, len(data_loader), step, data_time, epoch_loss_diff.avg))\n",
        "\n",
        "    data_start = time.time()\n",
        "\n",
        "    if epoch % decay == 0:\n",
        "        lr_now = lr_decay(optimizer, epoch, lr_init, decay, gamma)\n",
        "\n",
        "\n",
        "\n",
        "    print('test the performance of current model')\n",
        "\n",
        "    p1, p2 = test_hyber(edm_1=True, is_train=True)\n",
        "\n",
        "    if p1 < best_p1:\n",
        "        best_p1 = p1\n",
        "        best_epoch = epoch\n",
        "    print('| Best Epoch: {:0>4d} MPJPE: {:.2f} | Epoch: {:0>4d} MPJEPE: {:.2f} PA-MPJPE: {:.2f} |'\\\n",
        "        .format(best_epoch, best_p1, epoch, p1, p2))\n",
        "\n",
        "    loss_list_beta_2.append(epoch_loss_diff.avg)\n",
        "    p1_list_beta_2.append(p1)\n",
        "    p2_list_beta_2.append(p2)\n",
        "'''"
      ],
      "metadata": {
        "id": "Lg6L4vU2M2JH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "outputId": "b74af8be-54c8-4e8c-ad83-1ad77e1df1a0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Epoch0000: 0101/1524 | Step 000101 | Data: 7921.032238 | Loss: 60.319590 |\n",
            "| Epoch0000: 0201/1524 | Step 000201 | Data: 28929.829143 | Loss: 52.301847 |\n",
            "| Epoch0000: 0301/1524 | Step 000301 | Data: 63085.757681 | Loss: 47.434076 |\n",
            "| Epoch0000: 0401/1524 | Step 000401 | Data: 110074.526793 | Loss: 44.078708 |\n",
            "| Epoch0000: 0501/1524 | Step 000501 | Data: 169961.596749 | Loss: 41.506972 |\n",
            "| Epoch0000: 0601/1524 | Step 000601 | Data: 243180.954394 | Loss: 39.503878 |\n",
            "| Epoch0000: 0701/1524 | Step 000701 | Data: 329524.776556 | Loss: 37.908922 |\n",
            "| Epoch0000: 0801/1524 | Step 000801 | Data: 429253.489155 | Loss: 36.595162 |\n",
            "| Epoch0000: 0901/1524 | Step 000901 | Data: 541940.036229 | Loss: 35.498611 |\n",
            "| Epoch0000: 1001/1524 | Step 001001 | Data: 668121.819482 | Loss: 34.555452 |\n",
            "| Epoch0000: 1101/1524 | Step 001101 | Data: 807183.029080 | Loss: 33.732240 |\n",
            "| Epoch0000: 1201/1524 | Step 001201 | Data: 959304.238593 | Loss: 33.004564 |\n",
            "| Epoch0000: 1301/1524 | Step 001301 | Data: 1124643.471137 | Loss: 32.353329 |\n",
            "| Epoch0000: 1401/1524 | Step 001401 | Data: 1302917.326487 | Loss: 31.767877 |\n",
            "| Epoch0000: 1501/1524 | Step 001501 | Data: 1493752.964022 | Loss: 31.237004 |\n",
            "test the performance of current model\n",
            "Generating 543344 poses...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LinAlgError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-df8ec5dbbb41>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test the performance of current model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_hyber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medm_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_p1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-98bc0e16b9d2>\u001b[0m in \u001b[0;36mtest_hyber\u001b[0;34m(betas, test_times, test_timesteps, test_num_diffusion_timesteps, device, is_train, edm, edm_1)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mtargets_3d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mtargets_3d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mepoch_loss_3d_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpjpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mepoch_loss_3d_pos_procrustes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_mpjpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_xyz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdata_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-47c24ee8ec9e>\u001b[0m in \u001b[0;36mp_mpjpe\u001b[0;34m(predicted, target)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1658\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_svd_nonconvergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SVD did not converge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_lstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLinAlgError\u001b[0m: SVD did not converge"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "with open('loss4.txt', 'w') as file:\n",
        "    file.write('\\n'.join(str(l) for l in loss_list_beta_1_edm1))\n",
        "with open('p1_4.txt', 'w') as file:\n",
        "    file.write('\\n'.join(str(l) for l in p1_list_beta_1_edm1))\n",
        "with open('p2_4.txt', 'w') as file:\n",
        "    file.write('\\n'.join(str(l) for l in p2_list_beta_1_edm1))\n",
        "'''"
      ],
      "metadata": {
        "id": "YhBv1X8cM4kY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}